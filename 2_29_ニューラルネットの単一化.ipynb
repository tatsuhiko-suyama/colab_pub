{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting japanize_matplotlib\n",
      "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from japanize_matplotlib) (3.6.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (1.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.14.0)\n",
      "Building wheels for collected packages: japanize_matplotlib\n",
      "  Building wheel for japanize_matplotlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for japanize_matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120258 sha256=d1322597c0842dd5532a1d5a2d284f1ac19dbdc8fc7df3ed92a705367ae9e122\n",
      "  Stored in directory: /root/.cache/pip/wheels/8c/6b/86/8d53dd07a93ebf907e5ba60f380ee2f932880c25f7a55026e4\n",
      "Successfully built japanize_matplotlib\n",
      "Installing collected packages: japanize_matplotlib\n",
      "Successfully installed japanize_matplotlib-1.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting plotly\n",
      "  Downloading plotly-5.19.0-py3-none-any.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.0)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.19.0 tenacity-8.2.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install japanize_matplotlib\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.12522089 15.6625003   0.          0.          0.        ]\n",
      "0 2.881224315041891\n",
      "1000 5.859733493443969\n",
      "2000 5.863136341517361\n",
      "3000 5.863701233269808\n",
      "4000 5.863882103466324\n",
      "5000 5.8639570952783515\n",
      "6000 5.86399253472041\n",
      "7000 5.86401056315367\n",
      "8000 5.864020147041288\n",
      "9000 5.864025382339946\n",
      "10000 5.864028293063711\n",
      "11000 5.86402993060284\n",
      "12000 5.864030859340687\n",
      "13000 5.864031389104923\n",
      "14000 5.864031692667822\n",
      "15000 5.864031867297456\n",
      "16000 5.864031968040422\n",
      "17000 5.864032026307427\n",
      "18000 5.86403206007725\n",
      "19000 5.864032079691128\n",
      "20000 5.864032091101137\n",
      "21000 5.864032097750794\n",
      "22000 5.864032101632461\n",
      "23000 5.864032103904606\n",
      "24000 5.86403210523747\n",
      "25000 5.864032106022194\n",
      "26000 5.864032106486434\n",
      "27000 5.864032106763204\n",
      "28000 5.864032106929926\n",
      "29000 5.864032107032585\n",
      "30000 5.864032107096534\n",
      "31000 5.864032107137064\n",
      "32000 5.864032107164007\n",
      "33000 5.864032107182652\n",
      "34000 5.8640321071951576\n",
      "35000 5.86403210720448\n",
      "36000 5.864032107211585\n",
      "37000 5.864032107216644\n",
      "38000 5.864032107221249\n",
      "39000 5.864032107224034\n",
      "40000 5.864032107226535\n",
      "41000 5.86403210722915\n",
      "42000 5.864032107230514\n",
      "43000 5.864032107232447\n",
      "44000 5.864032107233697\n",
      "45000 5.864032107234948\n",
      "46000 5.864032107236028\n",
      "47000 5.864032107237108\n",
      "48000 5.864032107237904\n",
      "49000 5.864032107238529\n",
      "50000 5.8640321072390975\n",
      "51000 5.864032107239609\n",
      "52000 5.864032107240405\n",
      "53000 5.864032107240746\n",
      "54000 5.864032107241542\n",
      "55000 5.864032107242281\n",
      "56000 5.864032107242451\n",
      "57000 5.864032107242679\n",
      "58000 5.8640321072430766\n",
      "59000 5.864032107243304\n",
      "60000 5.864032107243588\n",
      "61000 5.864032107243986\n",
      "62000 5.864032107244327\n",
      "63000 5.864032107244043\n",
      "64000 5.8640321072445545\n",
      "65000 5.864032107244611\n",
      "66000 5.864032107245407\n",
      "67000 5.864032107245066\n",
      "68000 5.864032107245407\n",
      "69000 5.8640321072456345\n",
      "70000 5.86403210724626\n",
      "71000 5.864032107246203\n",
      "72000 5.864032107246089\n",
      "73000 5.864032107245748\n",
      "74000 5.864032107246658\n",
      "75000 5.864032107246544\n",
      "76000 5.864032107246999\n",
      "77000 5.864032107246658\n",
      "78000 5.864032107247112\n",
      "79000 5.864032107246601\n",
      "80000 5.864032107246771\n",
      "81000 5.864032107246999\n",
      "82000 5.864032107247112\n",
      "83000 5.86403210724751\n",
      "84000 5.864032107247567\n",
      "85000 5.864032107247681\n",
      "86000 5.8640321072474535\n",
      "87000 5.864032107247567\n",
      "88000 5.864032107247965\n",
      "89000 5.86403210724751\n",
      "90000 5.864032107247738\n",
      "91000 5.864032107247908\n",
      "92000 5.864032107247795\n",
      "93000 5.864032107248363\n",
      "94000 5.864032107247965\n",
      "95000 5.864032107248136\n",
      "96000 5.864032107248477\n",
      "97000 5.864032107248136\n",
      "98000 5.864032107248249\n",
      "99000 5.864032107248477\n",
      "処理時間 : 2400.394682860002,strike : 80,loss : 5.8640321072492725\n",
      "0 3.4383428942336423\n",
      "1000 10.0852592173419\n",
      "2000 10.092252687896973\n",
      "3000 10.093440091139144\n",
      "4000 10.093824466868568\n",
      "5000 10.093984970620852\n",
      "6000 10.094061235376728\n",
      "7000 10.09410020445398\n",
      "8000 10.094120996974027\n",
      "9000 10.094132391765356\n",
      "10000 10.094138744809328\n",
      "11000 10.094142327422787\n",
      "12000 10.094144363701332\n",
      "13000 10.09414552758426\n",
      "14000 10.094146195668316\n",
      "15000 10.09414658047615\n",
      "16000 10.09414680271891\n",
      "17000 10.094146931366566\n",
      "18000 10.094147005987395\n",
      "19000 10.09414704934892\n",
      "20000 10.094147074586829\n",
      "21000 10.09414708929853\n",
      "22000 10.094147097887003\n",
      "23000 10.094147102908124\n",
      "24000 10.094147105848265\n",
      "25000 10.094147107573463\n",
      "26000 10.094147108588515\n",
      "27000 10.094147109187759\n",
      "28000 10.094147109543883\n",
      "29000 10.094147109757017\n",
      "30000 10.094147109886478\n",
      "31000 10.09414710996623\n",
      "32000 10.094147110016337\n",
      "33000 10.094147110048993\n",
      "34000 10.094147110070594\n",
      "35000 10.094147110085515\n",
      "36000 10.094147110096031\n",
      "37000 10.094147110103876\n",
      "38000 10.094147110109759\n",
      "39000 10.094147110114193\n",
      "40000 10.09414711011783\n",
      "41000 10.094147110120502\n",
      "42000 10.094147110123004\n",
      "43000 10.094147110125022\n",
      "44000 10.094147110126642\n",
      "45000 10.094147110128063\n",
      "46000 10.094147110129256\n",
      "47000 10.09414711013028\n",
      "48000 10.094147110131246\n",
      "49000 10.094147110132155\n",
      "50000 10.094147110132951\n",
      "51000 10.09414711013352\n",
      "52000 10.094147110134202\n",
      "53000 10.094147110134656\n",
      "54000 10.094147110135339\n",
      "55000 10.094147110135765\n",
      "56000 10.094147110136163\n",
      "57000 10.094147110136475\n",
      "58000 10.094147110136845\n",
      "59000 10.094147110137158\n",
      "60000 10.094147110137612\n",
      "61000 10.094147110137953\n",
      "62000 10.09414711013821\n",
      "63000 10.094147110138351\n",
      "64000 10.094147110138692\n",
      "65000 10.09414711013892\n",
      "66000 10.094147110138977\n",
      "67000 10.094147110139232\n",
      "68000 10.094147110139488\n",
      "69000 10.09414711013983\n",
      "70000 10.094147110139602\n",
      "71000 10.094147110139943\n",
      "72000 10.09414711014017\n",
      "73000 10.09414711014034\n",
      "74000 10.094147110140398\n",
      "75000 10.094147110140568\n",
      "76000 10.094147110140625\n",
      "77000 10.094147110140796\n",
      "78000 10.094147110141023\n",
      "79000 10.094147110140966\n",
      "80000 10.094147110141137\n",
      "81000 10.09414711014125\n",
      "82000 10.094147110141307\n",
      "83000 10.094147110141535\n",
      "84000 10.094147110141478\n",
      "85000 10.094147110141591\n",
      "86000 10.094147110141762\n",
      "87000 10.094147110141762\n",
      "88000 10.09414711014179\n",
      "89000 10.09414711014196\n",
      "90000 10.094147110141876\n",
      "91000 10.094147110142103\n",
      "92000 10.09414711014216\n",
      "93000 10.094147110142217\n",
      "94000 10.094147110142217\n",
      "95000 10.094147110142217\n",
      "96000 10.09414711014233\n",
      "97000 10.0941471101425\n",
      "98000 10.09414711014253\n",
      "99000 10.094147110142643\n",
      "処理時間 : 2395.655964171514,strike : 90,loss : 10.094147110142785\n",
      "0 4.839007426180643\n",
      "1000 14.642825236858116\n",
      "2000 14.650497542804615\n",
      "3000 14.651789974609741\n",
      "4000 14.652205251199874\n",
      "5000 14.652377495023728\n",
      "6000 14.652458848361235\n",
      "7000 14.652500191986391\n",
      "8000 14.65252213961331\n",
      "9000 14.652534110570912\n",
      "10000 14.652540756522797\n",
      "11000 14.652544488721986\n",
      "12000 14.652546601799997\n",
      "13000 14.652547805348874\n",
      "14000 14.652548494022426\n",
      "15000 14.652548889581283\n",
      "16000 14.652549117341238\n",
      "17000 14.652549248840032\n",
      "18000 14.652549324945454\n",
      "19000 14.652549369079367\n",
      "20000 14.652549394714185\n",
      "21000 14.652549409629287\n",
      "22000 14.65254941832201\n",
      "23000 14.652549423396835\n",
      "24000 14.652549426364601\n",
      "25000 14.65254942810391\n",
      "26000 14.65254942912577\n",
      "27000 14.652549429728836\n",
      "28000 14.65254943008668\n",
      "29000 14.652549430301164\n",
      "30000 14.652549430431407\n",
      "31000 14.65254943051238\n",
      "32000 14.652549430563383\n",
      "33000 14.652549430596821\n",
      "34000 14.652549430619345\n",
      "35000 14.65254943063502\n",
      "36000 14.652549430646147\n",
      "37000 14.65254943065419\n",
      "38000 14.652549430660443\n",
      "39000 14.652549430665118\n",
      "40000 14.652549430668785\n",
      "41000 14.652549430671897\n",
      "42000 14.652549430674469\n",
      "43000 14.652549430676729\n",
      "44000 14.65254943067842\n",
      "45000 14.652549430679727\n",
      "46000 14.652549430681148\n",
      "47000 14.652549430682328\n",
      "48000 14.65254943068345\n",
      "49000 14.652549430684303\n",
      "50000 14.652549430684985\n",
      "51000 14.652549430685738\n",
      "52000 14.652549430686406\n",
      "53000 14.65254943068716\n",
      "54000 14.652549430687486\n",
      "55000 14.652549430688282\n",
      "56000 14.652549430688481\n",
      "57000 14.652549430689021\n",
      "58000 14.652549430689234\n",
      "59000 14.652549430689731\n",
      "60000 14.652549430690058\n",
      "61000 14.6525494306903\n",
      "62000 14.652549430690641\n",
      "63000 14.65254943069101\n",
      "64000 14.652549430691067\n",
      "65000 14.652549430691394\n",
      "66000 14.652549430691678\n",
      "67000 14.652549430691877\n",
      "68000 14.652549430692005\n",
      "69000 14.652549430692375\n",
      "70000 14.652549430692574\n",
      "71000 14.652549430692815\n",
      "72000 14.652549430692886\n",
      "73000 14.652549430693028\n",
      "74000 14.652549430693242\n",
      "75000 14.652549430693114\n",
      "76000 14.652549430693341\n",
      "77000 14.652549430693597\n",
      "78000 14.652549430693696\n",
      "79000 14.652549430693753\n",
      "80000 14.65254943069398\n",
      "81000 14.652549430694108\n",
      "82000 14.652549430694023\n",
      "83000 14.65254943069425\n",
      "84000 14.652549430694293\n",
      "85000 14.652549430694378\n",
      "86000 14.652549430694592\n",
      "87000 14.652549430694549\n",
      "88000 14.652549430694648\n",
      "89000 14.652549430694933\n",
      "90000 14.652549430695032\n",
      "91000 14.652549430695046\n",
      "92000 14.652549430695146\n",
      "93000 14.652549430694975\n",
      "94000 14.652549430695217\n",
      "95000 14.652549430695174\n",
      "96000 14.65254943069533\n",
      "97000 14.65254943069533\n",
      "98000 14.652549430695458\n",
      "99000 14.652549430695572\n",
      "処理時間 : 2391.952329998836,strike : 100,loss : 14.652549430695785\n",
      "0 3.6006399492339938\n",
      "1000 12.769832450797466\n",
      "2000 12.777520162076797\n",
      "3000 12.778820512378942\n",
      "4000 12.779240416442008\n",
      "5000 12.779415414496611\n",
      "6000 12.77949842107482\n",
      "7000 12.779540774059313\n",
      "8000 12.77956334367785\n",
      "9000 12.779575698619375\n",
      "10000 12.7795825799166\n",
      "11000 12.779586457209668\n",
      "12000 12.779588659387251\n",
      "13000 12.779589917369023\n",
      "14000 12.77959063910604\n",
      "15000 12.779591054664238\n",
      "16000 12.77959129460627\n",
      "21000 12.779591603940645\n",
      "22000 12.779591613213185\n",
      "23000 12.779591618634946\n",
      "29000 12.779591626022196\n",
      "30000 12.77959162615992\n",
      "31000 12.779591626244581\n",
      "32000 12.77959162629773\n",
      "33000 12.779591626332063\n",
      "34000 12.779591626355042\n",
      "35000 12.77959162637066\n",
      "36000 12.779591626381851\n",
      "37000 12.779591626389909\n",
      "38000 12.779591626396034\n",
      "39000 12.779591626400816\n",
      "40000 12.779591626404468\n",
      "41000 12.779591626407523\n",
      "42000 12.779591626409996\n",
      "43000 12.779591626411936\n",
      "44000 12.779591626413676\n",
      "45000 12.779591626415119\n",
      "46000 12.779591626416433\n",
      "47000 12.779591626417606\n",
      "48000 12.779591626418537\n",
      "49000 12.77959162641941\n",
      "50000 12.77959162642017\n",
      "51000 12.779591626420888\n",
      "52000 12.77959162642155\n",
      "53000 12.779591626422075\n",
      "54000 12.779591626422622\n",
      "55000 12.779591626423084\n",
      "56000 12.77959162642346\n",
      "57000 12.779591626423908\n",
      "58000 12.77959162642432\n",
      "59000 12.779591626424626\n",
      "60000 12.779591626425002\n",
      "61000 12.779591626425272\n",
      "62000 12.779591626425528\n",
      "63000 12.779591626425734\n",
      "69000 12.779591626427084\n",
      "70000 12.779591626427248\n",
      "71000 12.77959162642744\n",
      "72000 12.779591626427553\n",
      "73000 12.77959162642766\n",
      "74000 12.779591626427816\n",
      "75000 12.779591626427973\n",
      "76000 12.779591626428171\n",
      "77000 12.7795916264283\n",
      "78000 12.779591626428356\n",
      "79000 12.779591626428449\n",
      "80000 12.779591626428612\n",
      "81000 12.779591626428733\n",
      "82000 12.77959162642884\n",
      "83000 12.779591626428996\n",
      "84000 12.77959162642901\n",
      "85000 12.779591626429166\n",
      "86000 12.779591626429216\n",
      "87000 12.779591626429209\n",
      "88000 12.779591626429358\n",
      "89000 12.779591626429394\n",
      "90000 12.779591626429422\n",
      "91000 12.77959162642955\n",
      "92000 12.779591626429621\n",
      "93000 12.77959162642967\n",
      "94000 12.779591626429806\n",
      "95000 12.779591626429834\n",
      "96000 12.77959162642994\n",
      "97000 12.779591626429877\n",
      "98000 12.779591626429948\n",
      "99000 12.779591626430111\n",
      "処理時間 : 2391.3193431571126,strike : 110,loss : 12.779591626430204\n",
      "0 5.5376718609483575\n",
      "1000 18.663397104437205\n",
      "2000 18.669981377988268\n",
      "3000 18.671060012725075\n",
      "4000 18.671407136604135\n",
      "5000 18.671551867812575\n",
      "6000 18.67162062844899\n",
      "7000 18.67165577573541\n",
      "8000 18.671674541804386\n",
      "9000 18.671684832739498\n",
      "10000 18.67169057450542\n",
      "11000 18.671693814618898\n",
      "12000 18.67169565717874\n",
      "18000 18.671698050589157\n",
      "19000 18.671698089941337\n",
      "20000 18.671698112853292\n",
      "21000 18.67169812621927\n",
      "22000 18.67169813402689\n",
      "23000 18.671698138593612\n",
      "24000 18.671698141268315\n",
      "25000 18.6716981428384\n",
      "26000 18.671698143762494\n",
      "27000 18.671698144308486\n",
      "28000 18.67169814463316\n",
      "29000 18.671698144827978\n",
      "30000 18.67169814494664\n",
      "31000 18.671698145020212\n",
      "32000 18.671698145066856\n",
      "33000 18.671698145097274\n",
      "34000 18.671698145117702\n",
      "35000 18.671698145131842\n",
      "36000 18.671698145141924\n",
      "37000 18.671698145149392\n",
      "38000 18.671698145155027\n",
      "39000 18.671698145159382\n",
      "40000 18.671698145162893\n",
      "41000 18.671698145165685\n",
      "42000 18.671698145167955\n",
      "43000 18.671698145169994\n",
      "44000 18.6716981451716\n",
      "45000 18.67169814517301\n",
      "46000 18.67169814517427\n",
      "47000 18.67169814517529\n",
      "48000 18.671698145176286\n",
      "49000 18.671698145177103\n",
      "50000 18.671698145177842\n",
      "51000 18.67169814517853\n",
      "52000 18.671698145179153\n",
      "53000 18.67169814517976\n",
      "54000 18.671698145180233\n",
      "55000 18.671698145180734\n",
      "56000 18.671698145181203\n",
      "57000 18.671698145181566\n",
      "58000 18.67169814518197\n",
      "59000 18.671698145182297\n",
      "60000 18.6716981451826\n",
      "61000 18.671698145182866\n",
      "62000 18.67169814518315\n",
      "63000 18.671698145183438\n",
      "64000 18.67169814518368\n",
      "65000 18.67169814518391\n",
      "66000 18.67169814518409\n",
      "67000 18.671698145184337\n",
      "68000 18.67169814518452\n",
      "69000 18.671698145184727\n",
      "70000 18.671698145184862\n",
      "71000 18.671698145185047\n",
      "72000 18.671698145185182\n",
      "73000 18.671698145185346\n",
      "74000 18.67169814518548\n",
      "75000 18.671698145185648\n",
      "76000 18.671698145185765\n",
      "77000 18.671698145185864\n",
      "78000 18.671698145185992\n",
      "79000 18.67169814518617\n",
      "80000 18.671698145186227\n",
      "81000 18.67169814518631\n",
      "82000 18.67169814518641\n",
      "83000 18.671698145186532\n",
      "84000 18.671698145186596\n",
      "85000 18.671698145186706\n",
      "86000 18.671698145186795\n",
      "87000 18.671698145186852\n",
      "88000 18.67169814518699\n",
      "89000 18.671698145187065\n",
      "90000 18.671698145187133\n",
      "91000 18.671698145187165\n",
      "92000 18.671698145187307\n",
      "93000 18.67169814518732\n",
      "94000 18.67169814518742\n",
      "95000 18.671698145187445\n",
      "96000 18.67169814518752\n",
      "97000 18.671698145187577\n",
      "98000 18.671698145187637\n",
      "99000 18.671698145187694\n",
      "処理時間 : 2397.4389676637948,strike : 120,loss : 18.671698145187797\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>99278.0</td>\n",
       "      <td>1.713365e-12</td>\n",
       "      <td>0.847050</td>\n",
       "      <td>5.864032</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>8.526513e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>99638.0</td>\n",
       "      <td>6.828432e-13</td>\n",
       "      <td>0.706875</td>\n",
       "      <td>10.094147</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>1.421085e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>99847.0</td>\n",
       "      <td>5.277618e-13</td>\n",
       "      <td>0.558346</td>\n",
       "      <td>14.652549</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>2.131628e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>99939.0</td>\n",
       "      <td>5.954068e-13</td>\n",
       "      <td>0.408347</td>\n",
       "      <td>12.779592</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>7.105427e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>99549.0</td>\n",
       "      <td>6.961058e-13</td>\n",
       "      <td>0.258532</td>\n",
       "      <td>18.671698</td>\n",
       "      <td>2397.0</td>\n",
       "      <td>8.881784e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1             2         3          4       5             6\n",
       "0   80.0  99278.0  1.713365e-12  0.847050   5.864032  2400.0  8.526513e-14\n",
       "0   90.0  99638.0  6.828432e-13  0.706875  10.094147  2395.0  1.421085e-14\n",
       "0  100.0  99847.0  5.277618e-13  0.558346  14.652549  2391.0  2.131628e-14\n",
       "0  110.0  99939.0  5.954068e-13  0.408347  12.779592  2391.0  7.105427e-15\n",
       "0  120.0  99549.0  6.961058e-13  0.258532  18.671698  2397.0  8.881784e-15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#@title 関数　ストラングル 3\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "#満期の株価\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#満期\n",
    "maturity = 4 # @param\n",
    "\n",
    "#時間間隔\n",
    "dt=1/maturity#@param\n",
    "\n",
    "\n",
    "sigma_ave=0.3 # @param\n",
    "mu_ave=0.05-sigma_ave**2/2#@param\n",
    "S_0 = 100  # @param\n",
    "strike = 120  # @param\n",
    "branches_bin=2#@param\n",
    "\n",
    "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
    "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
    "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
    "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "print(Call_T)\n",
    "for n in np.arange(maturity-1,-1,-1):\n",
    "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "\n",
    "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "init_cost=Call_T[0]\n",
    "\n",
    "\n",
    "\n",
    "#3項モデルでのパラメータを設定する\n",
    "branches = 3  # @param\n",
    "nu=0.005#@param\n",
    "zeta=0.35#@param\n",
    "# 上昇率\n",
    "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_cost\n",
    "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#コールオプションの支払い\n",
    "def call(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(stock_price-strike,0)\n",
    "#プットオプションの支払い\n",
    "def put(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(strike-stock_price,0)\n",
    "#パラメータから確率測度を計算\n",
    "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
    "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
    "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
    "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
    "  return prob\n",
    "import numpy as np\n",
    "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
    "    return x.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "payoff='call'\n",
    "#最適ヘッジの計算\n",
    "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
    "    #初期条件\n",
    "    #maturity : 満期\n",
    "    #branches : 分岐数\n",
    "    #up : 上昇因子\n",
    "    #down : 下降因子\n",
    "    #S_0 : 初期株価\n",
    "    #init_cost : 初期コスト\n",
    "    #prob_matrix : 推移確率\n",
    "    #payoff_func : 支払い関数\n",
    "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
    "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
    "    assert up>1 #上昇因子は1より大きい実数\n",
    "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
    "    assert S_0>=0\n",
    "    assert init_cost>=0\n",
    "    import numpy as np\n",
    "    data = []\n",
    "    delta_S=[]\n",
    "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
    "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
    "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
    "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
    "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
    "\n",
    "    if payoff=='call':\n",
    "      #コール\n",
    "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
    "    if payoff=='strangle':\n",
    "      #ストラングル\n",
    "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    if payoff=='bull':\n",
    "      #ブルスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    elif payoff=='batafrei':\n",
    "      #バタフライスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "      prob_tensor=prob_list[n]\n",
    "      a_n= a_n.unfold(0,branches, 1)\n",
    "      b_n=b_n.unfold(0,branches, 1)\n",
    "      c_n= c_n.unfold(0,branches, 1)\n",
    "      stock_price = stock_price.unfold(0,branches,1)\n",
    "      #条件付き期待値を計算\n",
    "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
    "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
    "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
    "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
    "\n",
    "      stock_price=(stock_price/up)[:,0]\n",
    "      #a, b, cの更新\n",
    "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_n=Cond_Exp_a-a_divide\n",
    "      b_n=Cond_Exp_b-a_b_divide\n",
    "      c_n=Cond_Exp_c-b_divide\n",
    "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
    "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
    "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
    "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
    "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
    "    Hedge_Error\n",
    "    return Hedge_Error,pi_0,init_cost_opt,df\n",
    "\n",
    "\n",
    "\n",
    "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "strike_range =np.arange(80,130,10)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        return (x - mean) / std\n",
    "normalize = Normalize()\n",
    "def tensor_to_standard(input_tensor):\n",
    "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "def decimal_to_base_n(n, base):\n",
    "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, base)\n",
    "        nums.append(str(r))\n",
    "    return int(''.join(reversed(nums)))\n",
    "df=pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for strike in strike_range:\n",
    " \n",
    "    if payoff=='call':\n",
    "        #コール\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "    if payoff=='strangle':\n",
    "        #ストラングル\n",
    "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    if payoff=='bull':\n",
    "        #ブルスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    elif payoff=='batafrei':\n",
    "        #バタフライスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "\n",
    "\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "    init_cost=Call_T[0]\n",
    "    end_epoch = []\n",
    "    prob_list_bust = []\n",
    "    df_weight = pd.DataFrame()\n",
    "\n",
    "    df_pi_0 = pd.DataFrame()\n",
    "    prob_df = []\n",
    "    pi_0s=[]\n",
    "    losses = []\n",
    "    weights = []\n",
    "    grads = []\n",
    "    error_True = []\n",
    "\n",
    "\n",
    "    def call(strike=strike, stock_price=stock_price_T):\n",
    "        stock_price = stock_price_T()\n",
    "        return np.maximum(stock_price - strike, 0)\n",
    "    #Heの初期化\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
    "\n",
    "    model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
    "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
    "\n",
    "\n",
    "    models = model_params.shape[0]\n",
    "    torch.cuda.seed_all()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input_size = 9\n",
    "    hidden_size = 2**8\n",
    "    output_size = models\n",
    "\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc_add1=nn.Linear(input_size,input_size)\n",
    "            self.fc_add2=nn.Linear(input_size,input_size)\n",
    "            self.layers = nn.Sequential()\n",
    "\n",
    "            # 入力層\n",
    "            #1層\n",
    "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
    "\n",
    "\n",
    "            #2層\n",
    "            activation=nn.ReLU()\n",
    "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu{0}\", activation)\n",
    "            self.layers.add_module(f\"st{0}\", normalize)\n",
    "            units=5\n",
    "            for i in np.arange(1,units,1):\n",
    "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
    "                self.layers.add_module(f\"relu{i}\",activation)\n",
    "                self.layers.add_module(f\"st{i}\", normalize)\n",
    "\n",
    "           \n",
    "\n",
    "            #3層\n",
    "        \n",
    "\n",
    "            #4層\n",
    "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu_final\", activation)\n",
    "\n",
    "\n",
    "            # 出力層\n",
    "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "\n",
    "    net =NN().cuda().double()\n",
    "  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0005) \n",
    "\n",
    "\n",
    "    num_epochs =10**5\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
    "        new_weight_tensor = weight_tensor.clone()\n",
    "\n",
    "\n",
    "        for n in np.arange(maturity-1, 0, -1):\n",
    "\n",
    "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
    "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
    "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
    "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
    "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "\n",
    "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
    "\n",
    "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
    "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
    "        weight_tensor = new_weight_tensor\n",
    "\n",
    "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
    "        new_prob_tensor=prob_tensor.clone()\n",
    "        for m in range(models):\n",
    "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
    "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
    "\n",
    "        new_prob_tensor\n",
    "        prob_list=[]\n",
    "        for n in range(new_prob_tensor.shape[0]):\n",
    "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
    "\n",
    "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
    "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
    "        pi_0s.append(pi_0.item())\n",
    "        weights.append(weight_tensor.detach().cpu().numpy())\n",
    "        losses.append(-loss.item())\n",
    "        if epoch % 1000==0:\n",
    "            print(epoch,-loss.item())\n",
    "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time=time.perf_counter() - t0\n",
    "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
    "\n",
    "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
    "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
    "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
    "\n",
    "\n",
    "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
    "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
    "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov.csv',index=False)\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # 1万個のデータを準備\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    # lossesの勾配を計算\n",
    "    gradient_losses = np.gradient(losses)\n",
    "\n",
    "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
    "    indices = np.arange(1, len(losses), 100)\n",
    "\n",
    "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
    "    selected_losses = losses[indices]\n",
    "    selected_gradient_losses = gradient_losses[indices]\n",
    "\n",
    "    # lossesとgradient_lossesから最大値を取得\n",
    "    max_loss = np.max(losses)\n",
    "    max_gradient_loss = np.max(gradient_losses)\n",
    "\n",
    "    # 最大値のインデックスを取得\n",
    "    index_max_loss = np.argmax(losses)\n",
    "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
    "\n",
    "    # プロットの作成\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
    "\n",
    "    # gradient_lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
    "\n",
    "    # グラフのタイトルと軸ラベルの設定\n",
    "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
    "                  xaxis_title='エポック数',\n",
    "                  yaxis_title='ヘッジ誤差')\n",
    "\n",
    "    # グラフをHTMLファイルとして保存\n",
    "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
    "\n",
    "    # グラフの表示\n",
    "\n",
    "    step=1\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
    "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
    "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
    "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.12522089 15.6625003   0.          0.          0.        ]\n",
      "0 2.2121086817317064\n",
      "1000 5.87141671620293\n",
      "2000 5.877949417254115\n",
      "3000 5.878892465080639\n",
      "4000 5.879184971281916\n",
      "5000 5.879304574666776\n",
      "6000 5.879360994220974\n",
      "7000 5.879389797463432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=335'>336</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(new_prob_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=336'>337</a>\u001b[0m     prob_list\u001b[39m.\u001b[39mappend(new_prob_tensor[n][\u001b[39m0\u001b[39m:(branches\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mn\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreshape((branches\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mn\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,branches))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=338'>339</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mcalculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=339'>340</a>\u001b[0m pi_0\u001b[39m=\u001b[39mcalculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=340'>341</a>\u001b[0m pi_0s\u001b[39m.\u001b[39mappend(pi_0\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m   b_n\u001b[39m=\u001b[39mCond_Exp_b\u001b[39m-\u001b[39ma_b_divide\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m   c_n\u001b[39m=\u001b[39mCond_Exp_c\u001b[39m-\u001b[39mb_divide\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m df\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([df,pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39ma_n\u001b[39m\u001b[39m'\u001b[39m :to_numpy(a_n),\u001b[39m'\u001b[39m\u001b[39mb_n\u001b[39m\u001b[39m'\u001b[39m:to_numpy(b_n),\u001b[39m'\u001b[39m\u001b[39mc_n\u001b[39m\u001b[39m'\u001b[39m: to_numpy(c_n), \u001b[39m'\u001b[39m\u001b[39mstock_price\u001b[39m\u001b[39m'\u001b[39m: to_numpy(stock_price), \u001b[39m'\u001b[39m\u001b[39mCond_Exp_a\u001b[39m\u001b[39m'\u001b[39m: to_numpy(Cond_Exp_a), \u001b[39m'\u001b[39m\u001b[39mCond_Exp_a_Delta_S\u001b[39m\u001b[39m'\u001b[39m: to_numpy(Cond_Exp_a_Delta_S), \u001b[39m'\u001b[39m\u001b[39mCond_Exp_a_Delta_S_sq\u001b[39m\u001b[39m'\u001b[39m: to_numpy(Cond_Exp_a_Delta_S_sq), \u001b[39m'\u001b[39m\u001b[39mCond_Exp_b\u001b[39m\u001b[39m'\u001b[39m: to_numpy(Cond_Exp_b), \u001b[39m'\u001b[39m\u001b[39mCond_Exp_b_Delta_S\u001b[39m\u001b[39m'\u001b[39m: to_numpy(Cond_Exp_b_Delta_S), \u001b[39m'\u001b[39m\u001b[39mCond_Exp_c\u001b[39m\u001b[39m'\u001b[39m: to_numpy(Cond_Exp_c),\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq\u001b[39m\u001b[39m'\u001b[39m : to_numpy((Cond_Exp_a_Delta_S)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m/\u001b[39mCond_Exp_a_Delta_S_sq),\u001b[39m'\u001b[39m\u001b[39m(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq\u001b[39m\u001b[39m'\u001b[39m : to_numpy((Cond_Exp_a_Delta_S)\u001b[39m*\u001b[39m(Cond_Exp_b_Delta_S)\u001b[39m/\u001b[39mCond_Exp_a_Delta_S_sq),\u001b[39m'\u001b[39m\u001b[39m(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq\u001b[39m\u001b[39m'\u001b[39m : to_numpy((Cond_Exp_b_Delta_S)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m/\u001b[39mCond_Exp_a_Delta_S_sq)})], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m Hedge_Error \u001b[39m=\u001b[39m a_n\u001b[39m*\u001b[39minit_cost\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mb_n\u001b[39m*\u001b[39minit_cost\u001b[39m+\u001b[39mc_n\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m pi_0 \u001b[39m=\u001b[39m Cond_Exp_b_Delta_S\u001b[39m/\u001b[39mCond_Exp_a_Delta_S_sq\u001b[39m-\u001b[39minit_cost\u001b[39m*\u001b[39mCond_Exp_a_Delta_S\u001b[39m/\u001b[39mCond_Exp_a_Delta_S_sq\n",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_numpy\u001b[39m(x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W2sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#@title 関数　ストラングル 3\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "#満期の株価\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#満期\n",
    "maturity = 4 # @param\n",
    "\n",
    "#時間間隔\n",
    "dt=1/maturity#@param\n",
    "\n",
    "\n",
    "sigma_ave=0.3 # @param\n",
    "mu_ave=0.05-sigma_ave**2/2#@param\n",
    "S_0 = 100  # @param\n",
    "strike = 120  # @param\n",
    "branches_bin=2#@param\n",
    "\n",
    "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
    "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
    "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
    "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "print(Call_T)\n",
    "for n in np.arange(maturity-1,-1,-1):\n",
    "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "\n",
    "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "init_cost=Call_T[0]\n",
    "\n",
    "\n",
    "\n",
    "#3項モデルでのパラメータを設定する\n",
    "branches = 3  # @param\n",
    "nu=0.005#@param\n",
    "zeta=0.35#@param\n",
    "# 上昇率\n",
    "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_cost\n",
    "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#コールオプションの支払い\n",
    "def call(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(stock_price-strike,0)\n",
    "#プットオプションの支払い\n",
    "def put(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(strike-stock_price,0)\n",
    "#パラメータから確率測度を計算\n",
    "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
    "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
    "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
    "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
    "  return prob\n",
    "import numpy as np\n",
    "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
    "    return x.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "payoff='call'\n",
    "#最適ヘッジの計算\n",
    "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
    "    #初期条件\n",
    "    #maturity : 満期\n",
    "    #branches : 分岐数\n",
    "    #up : 上昇因子\n",
    "    #down : 下降因子\n",
    "    #S_0 : 初期株価\n",
    "    #init_cost : 初期コスト\n",
    "    #prob_matrix : 推移確率\n",
    "    #payoff_func : 支払い関数\n",
    "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
    "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
    "    assert up>1 #上昇因子は1より大きい実数\n",
    "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
    "    assert S_0>=0\n",
    "    assert init_cost>=0\n",
    "    import numpy as np\n",
    "    data = []\n",
    "    delta_S=[]\n",
    "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
    "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
    "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
    "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
    "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
    "\n",
    "    if payoff=='call':\n",
    "      #コール\n",
    "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
    "    if payoff=='strangle':\n",
    "      #ストラングル\n",
    "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    if payoff=='bull':\n",
    "      #ブルスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    elif payoff=='batafrei':\n",
    "      #バタフライスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "      prob_tensor=prob_list[n]\n",
    "      a_n= a_n.unfold(0,branches, 1)\n",
    "      b_n=b_n.unfold(0,branches, 1)\n",
    "      c_n= c_n.unfold(0,branches, 1)\n",
    "      stock_price = stock_price.unfold(0,branches,1)\n",
    "      #条件付き期待値を計算\n",
    "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
    "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
    "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
    "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
    "\n",
    "      stock_price=(stock_price/up)[:,0]\n",
    "      #a, b, cの更新\n",
    "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_n=Cond_Exp_a-a_divide\n",
    "      b_n=Cond_Exp_b-a_b_divide\n",
    "      c_n=Cond_Exp_c-b_divide\n",
    "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
    "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
    "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
    "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
    "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
    "    Hedge_Error\n",
    "    return Hedge_Error,pi_0,init_cost_opt,df\n",
    "\n",
    "\n",
    "\n",
    "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "strike_range =np.arange(80,130,10)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        return (x - mean) / std\n",
    "normalize = Normalize()\n",
    "def tensor_to_standard(input_tensor):\n",
    "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "def decimal_to_base_n(n, base):\n",
    "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, base)\n",
    "        nums.append(str(r))\n",
    "    return int(''.join(reversed(nums)))\n",
    "df=pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for strike in strike_range:\n",
    " \n",
    "    if payoff=='call':\n",
    "        #コール\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "    if payoff=='strangle':\n",
    "        #ストラングル\n",
    "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    if payoff=='bull':\n",
    "        #ブルスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    elif payoff=='batafrei':\n",
    "        #バタフライスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "\n",
    "\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "    init_cost=Call_T[0]\n",
    "    end_epoch = []\n",
    "    prob_list_bust = []\n",
    "    df_weight = pd.DataFrame()\n",
    "\n",
    "    df_pi_0 = pd.DataFrame()\n",
    "    prob_df = []\n",
    "    pi_0s=[]\n",
    "    losses = []\n",
    "    weights = []\n",
    "    grads = []\n",
    "    error_True = []\n",
    "\n",
    "\n",
    "    def call(strike=strike, stock_price=stock_price_T):\n",
    "        stock_price = stock_price_T()\n",
    "        return np.maximum(stock_price - strike, 0)\n",
    "    #Heの初期化\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
    "\n",
    "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
    "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
    "\n",
    "\n",
    "    models = model_params.shape[0]\n",
    "    torch.cuda.seed_all()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input_size = 9\n",
    "    hidden_size = 2**8\n",
    "    output_size = models\n",
    "\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc_add1=nn.Linear(input_size,input_size)\n",
    "            self.fc_add2=nn.Linear(input_size,input_size)\n",
    "            self.layers = nn.Sequential()\n",
    "\n",
    "            # 入力層\n",
    "            #1層\n",
    "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
    "\n",
    "\n",
    "            #2層\n",
    "            activation=nn.ReLU()\n",
    "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu{0}\", activation)\n",
    "            self.layers.add_module(f\"st{0}\", normalize)\n",
    "            units=15\n",
    "            for i in np.arange(1,units,1):\n",
    "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
    "                self.layers.add_module(f\"relu{i}\",activation)\n",
    "                self.layers.add_module(f\"st{i}\", normalize)\n",
    "\n",
    "           \n",
    "\n",
    "            #3層\n",
    "        \n",
    "\n",
    "            #4層\n",
    "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu_final\", activation)\n",
    "\n",
    "\n",
    "            # 出力層\n",
    "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "\n",
    "    net =NN().cuda().double()\n",
    "  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0005) \n",
    "\n",
    "\n",
    "    num_epochs =10**5\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
    "        new_weight_tensor = weight_tensor.clone()\n",
    "\n",
    "\n",
    "        for n in np.arange(maturity-1, 0, -1):\n",
    "\n",
    "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
    "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
    "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
    "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
    "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "\n",
    "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
    "\n",
    "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
    "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
    "        weight_tensor = new_weight_tensor\n",
    "\n",
    "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
    "        new_prob_tensor=prob_tensor.clone()\n",
    "        for m in range(models):\n",
    "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
    "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
    "\n",
    "        new_prob_tensor\n",
    "        prob_list=[]\n",
    "        for n in range(new_prob_tensor.shape[0]):\n",
    "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
    "\n",
    "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
    "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
    "        pi_0s.append(pi_0.item())\n",
    "        weights.append(weight_tensor.detach().cpu().numpy())\n",
    "        losses.append(-loss.item())\n",
    "        if epoch % 1000==0:\n",
    "            print(epoch,-loss.item())\n",
    "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time=time.perf_counter() - t0\n",
    "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
    "\n",
    "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
    "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
    "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
    "\n",
    "\n",
    "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
    "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
    "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov.csv',index=False)\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # 1万個のデータを準備\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    # lossesの勾配を計算\n",
    "    gradient_losses = np.gradient(losses)\n",
    "\n",
    "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
    "    indices = np.arange(1, len(losses), 100)\n",
    "\n",
    "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
    "    selected_losses = losses[indices]\n",
    "    selected_gradient_losses = gradient_losses[indices]\n",
    "\n",
    "    # lossesとgradient_lossesから最大値を取得\n",
    "    max_loss = np.max(losses)\n",
    "    max_gradient_loss = np.max(gradient_losses)\n",
    "\n",
    "    # 最大値のインデックスを取得\n",
    "    index_max_loss = np.argmax(losses)\n",
    "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
    "\n",
    "    # プロットの作成\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
    "\n",
    "    # gradient_lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
    "\n",
    "    # グラフのタイトルと軸ラベルの設定\n",
    "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
    "                  xaxis_title='エポック数',\n",
    "                  yaxis_title='ヘッジ誤差')\n",
    "\n",
    "    # グラフをHTMLファイルとして保存\n",
    "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
    "\n",
    "    # グラフの表示\n",
    "\n",
    "    step=1\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
    "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
    "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
    "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.12522089 15.6625003   0.          0.          0.        ]\n",
      "0 2.9256700674185367\n",
      "100 3.9608898365005416\n",
      "200 4.608412141457848\n",
      "300 4.796635420891334\n",
      "400 4.444242195925369\n",
      "500 4.869484786801991\n",
      "600 5.050219277603674\n",
      "700 5.099790361083535\n",
      "800 5.197541235484664\n",
      "900 5.214513393786433\n",
      "1000 5.271191239461814\n",
      "1100 5.372573052877442\n",
      "1200 5.408981916521384\n",
      "1300 5.447779046200367\n",
      "1400 5.486350490136658\n",
      "1500 5.507818255891095\n",
      "1600 5.54588540378586\n",
      "1700 5.5628466937683925\n",
      "1800 5.587633790142149\n",
      "1900 5.6041285678192025\n",
      "2000 5.613072001688636\n",
      "2100 5.628531102072998\n",
      "2200 5.636904595405667\n",
      "2300 5.646838121078986\n",
      "2400 5.649095340348481\n",
      "2500 5.659824160783842\n",
      "2600 5.664728170114472\n",
      "2700 5.668839197609486\n",
      "2800 5.672560204530782\n",
      "2900 5.675849872143999\n",
      "3000 5.678712976147267\n",
      "3100 5.681090757348272\n",
      "3200 5.6832683166003335\n",
      "3300 5.683966153095469\n",
      "3400 5.6867820437755086\n",
      "3500 5.688254056111077\n",
      "3600 5.6895649032098845\n",
      "3700 5.690706369222312\n",
      "3800 5.691771336930458\n",
      "3900 5.692690462120254\n",
      "4000 5.693566100392616\n",
      "4100 5.694156656131099\n",
      "4200 5.695025067359893\n",
      "4300 5.695635022023282\n",
      "4400 5.696217604806179\n",
      "4500 5.696729358263838\n",
      "4600 5.697210692152453\n",
      "4700 5.697637145205022\n",
      "4800 5.698025684151389\n",
      "4900 5.698396033269091\n",
      "5000 5.698726441496149\n",
      "5100 5.699016608154295\n",
      "5200 5.699317245530494\n",
      "5300 5.699577038052553\n",
      "5400 5.699813182277751\n",
      "5500 5.700036091619154\n",
      "5600 5.700238220860854\n",
      "5700 5.700428750903427\n",
      "5800 5.700602615804428\n",
      "5900 5.700762930204178\n",
      "6000 5.700866491449233\n",
      "6100 5.7010244909421885\n",
      "6200 5.701182917372648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=316'>317</a>\u001b[0m     input_tensor\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mconcat([current_time,current_time\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m,current_time\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m,torch\u001b[39m.\u001b[39mlog(S),torch\u001b[39m.\u001b[39mlog(S)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m,torch\u001b[39m.\u001b[39mlog(S)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m,\\\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=317'>318</a>\u001b[0m                         torch\u001b[39m.\u001b[39msqrt(S), torch\u001b[39m.\u001b[39msqrt(S)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m , torch\u001b[39m.\u001b[39msqrt(S)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m],dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=318'>319</a>\u001b[0m     ST_input_tensor\u001b[39m=\u001b[39m(input_tensor\u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mmean(input_tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\u001b[39m/\u001b[39m(torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39mvar(input_tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unbiased\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m+\u001b[39m\u001b[39m1e-05\u001b[39m))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=320'>321</a>\u001b[0m     new_weight_tensor[n][\u001b[39m0\u001b[39m:(branches\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39m(n\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)(net(ST_input_tensor\u001b[39m.\u001b[39;49mcuda()\u001b[39m.\u001b[39;49mdouble()))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=322'>323</a>\u001b[0m input_tensor\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor([[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]])\u001b[39m.\u001b[39mcuda()\u001b[39m.\u001b[39mdouble()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=323'>324</a>\u001b[0m ST_input_tensor\u001b[39m=\u001b[39m(input_tensor\u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mmean(input_tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\u001b[39m/\u001b[39m(torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39mvar(input_tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unbiased\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m+\u001b[39m\u001b[39m1e-05\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=287'>288</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=288'>289</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m     mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(x, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m     std \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39msqrt(torch\u001b[39m.\u001b[39;49mvar(x, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, unbiased\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m+\u001b[39;49m\u001b[39m1e-05\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W4sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (x \u001b[39m-\u001b[39m mean) \u001b[39m/\u001b[39m std\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#@title 関数　ストラングル 3\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "#満期の株価\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#満期\n",
    "maturity = 4 # @param\n",
    "\n",
    "#時間間隔\n",
    "dt=1/maturity#@param\n",
    "\n",
    "\n",
    "sigma_ave=0.3 # @param\n",
    "mu_ave=0.05-sigma_ave**2/2#@param\n",
    "S_0 = 100  # @param\n",
    "strike = 120  # @param\n",
    "branches_bin=2#@param\n",
    "\n",
    "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
    "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
    "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
    "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "print(Call_T)\n",
    "for n in np.arange(maturity-1,-1,-1):\n",
    "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "\n",
    "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "init_cost=Call_T[0]\n",
    "\n",
    "\n",
    "\n",
    "#3項モデルでのパラメータを設定する\n",
    "branches = 3  # @param\n",
    "nu=0.005#@param\n",
    "zeta=0.35#@param\n",
    "# 上昇率\n",
    "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_cost\n",
    "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#コールオプションの支払い\n",
    "def call(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(stock_price-strike,0)\n",
    "#プットオプションの支払い\n",
    "def put(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(strike-stock_price,0)\n",
    "#パラメータから確率測度を計算\n",
    "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
    "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
    "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
    "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
    "  return prob\n",
    "import numpy as np\n",
    "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
    "    return x.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "payoff='call'\n",
    "#最適ヘッジの計算\n",
    "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
    "    #初期条件\n",
    "    #maturity : 満期\n",
    "    #branches : 分岐数\n",
    "    #up : 上昇因子\n",
    "    #down : 下降因子\n",
    "    #S_0 : 初期株価\n",
    "    #init_cost : 初期コスト\n",
    "    #prob_matrix : 推移確率\n",
    "    #payoff_func : 支払い関数\n",
    "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
    "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
    "    assert up>1 #上昇因子は1より大きい実数\n",
    "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
    "    assert S_0>=0\n",
    "    assert init_cost>=0\n",
    "    import numpy as np\n",
    "    data = []\n",
    "    delta_S=[]\n",
    "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
    "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
    "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
    "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
    "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
    "\n",
    "    if payoff=='call':\n",
    "      #コール\n",
    "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
    "    if payoff=='strangle':\n",
    "      #ストラングル\n",
    "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    if payoff=='bull':\n",
    "      #ブルスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    elif payoff=='batafrei':\n",
    "      #バタフライスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "      prob_tensor=prob_list[n]\n",
    "      a_n= a_n.unfold(0,branches, 1)\n",
    "      b_n=b_n.unfold(0,branches, 1)\n",
    "      c_n= c_n.unfold(0,branches, 1)\n",
    "      stock_price = stock_price.unfold(0,branches,1)\n",
    "      #条件付き期待値を計算\n",
    "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
    "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
    "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
    "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
    "\n",
    "      stock_price=(stock_price/up)[:,0]\n",
    "      #a, b, cの更新\n",
    "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_n=Cond_Exp_a-a_divide\n",
    "      b_n=Cond_Exp_b-a_b_divide\n",
    "      c_n=Cond_Exp_c-b_divide\n",
    "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
    "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
    "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
    "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
    "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
    "    Hedge_Error\n",
    "    return Hedge_Error,pi_0,init_cost_opt,df\n",
    "\n",
    "\n",
    "\n",
    "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "strike_range =np.arange(80,130,10)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        return (x - mean) / std\n",
    "normalize = Normalize()\n",
    "def tensor_to_standard(input_tensor):\n",
    "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "def decimal_to_base_n(n, base):\n",
    "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, base)\n",
    "        nums.append(str(r))\n",
    "    return int(''.join(reversed(nums)))\n",
    "df=pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for strike in strike_range:\n",
    " \n",
    "    if payoff=='call':\n",
    "        #コール\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "    if payoff=='strangle':\n",
    "        #ストラングル\n",
    "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    if payoff=='bull':\n",
    "        #ブルスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    elif payoff=='batafrei':\n",
    "        #バタフライスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "\n",
    "\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "    init_cost=Call_T[0]\n",
    "    end_epoch = []\n",
    "    prob_list_bust = []\n",
    "    df_weight = pd.DataFrame()\n",
    "\n",
    "    df_pi_0 = pd.DataFrame()\n",
    "    prob_df = []\n",
    "    pi_0s=[]\n",
    "    losses = []\n",
    "    weights = []\n",
    "    grads = []\n",
    "    error_True = []\n",
    "\n",
    "\n",
    "    def call(strike=strike, stock_price=stock_price_T):\n",
    "        stock_price = stock_price_T()\n",
    "        return np.maximum(stock_price - strike, 0)\n",
    "    #Heの初期化\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
    "\n",
    "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
    "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
    "\n",
    "\n",
    "    models = model_params.shape[0]\n",
    "    torch.cuda.seed_all()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input_size = 9\n",
    "    hidden_size = 2**8\n",
    "    output_size = models\n",
    "\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc_add1=nn.Linear(input_size,input_size)\n",
    "            self.fc_add2=nn.Linear(input_size,input_size)\n",
    "            self.layers = nn.Sequential()\n",
    "\n",
    "            # 入力層\n",
    "            #1層\n",
    "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
    "\n",
    "\n",
    "            #2層\n",
    "            activation=nn.ReLU()\n",
    "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu{0}\", activation)\n",
    "            self.layers.add_module(f\"st{0}\", normalize)\n",
    "            units=20\n",
    "            for i in np.arange(1,units,1):\n",
    "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
    "                self.layers.add_module(f\"relu{i}\",activation)\n",
    "                self.layers.add_module(f\"st{i}\", normalize)\n",
    "\n",
    "           \n",
    "\n",
    "            #3層\n",
    "        \n",
    "\n",
    "            #4層\n",
    "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu_final\", activation)\n",
    "\n",
    "\n",
    "            # 出力層\n",
    "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "\n",
    "    net =NN().cuda().double()\n",
    "  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001) \n",
    "\n",
    "\n",
    "    num_epochs =10**5\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
    "        new_weight_tensor = weight_tensor.clone()\n",
    "\n",
    "\n",
    "        for n in np.arange(maturity-1, 0, -1):\n",
    "\n",
    "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
    "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
    "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
    "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
    "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "\n",
    "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
    "\n",
    "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
    "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
    "        weight_tensor = new_weight_tensor\n",
    "\n",
    "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
    "        new_prob_tensor=prob_tensor.clone()\n",
    "        for m in range(models):\n",
    "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
    "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
    "\n",
    "        new_prob_tensor\n",
    "        prob_list=[]\n",
    "        for n in range(new_prob_tensor.shape[0]):\n",
    "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
    "\n",
    "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
    "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
    "        pi_0s.append(pi_0.item())\n",
    "        weights.append(weight_tensor.detach().cpu().numpy())\n",
    "        losses.append(-loss.item())\n",
    "        if epoch % 100==0:\n",
    "            print(epoch,-loss.item())\n",
    "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time=time.perf_counter() - t0\n",
    "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
    "\n",
    "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
    "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
    "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
    "\n",
    "\n",
    "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
    "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
    "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov.csv',index=False)\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # 1万個のデータを準備\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    # lossesの勾配を計算\n",
    "    gradient_losses = np.gradient(losses)\n",
    "\n",
    "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
    "    indices = np.arange(1, len(losses), 100)\n",
    "\n",
    "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
    "    selected_losses = losses[indices]\n",
    "    selected_gradient_losses = gradient_losses[indices]\n",
    "\n",
    "    # lossesとgradient_lossesから最大値を取得\n",
    "    max_loss = np.max(losses)\n",
    "    max_gradient_loss = np.max(gradient_losses)\n",
    "\n",
    "    # 最大値のインデックスを取得\n",
    "    index_max_loss = np.argmax(losses)\n",
    "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
    "\n",
    "    # プロットの作成\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
    "\n",
    "    # gradient_lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
    "\n",
    "    # グラフのタイトルと軸ラベルの設定\n",
    "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
    "                  xaxis_title='エポック数',\n",
    "                  yaxis_title='ヘッジ誤差')\n",
    "\n",
    "    # グラフをHTMLファイルとして保存\n",
    "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
    "\n",
    "    # グラフの表示\n",
    "\n",
    "    step=1\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
    "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
    "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
    "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.12522089 15.6625003   0.          0.          0.        ]\n",
      "0 2.756825814759509\n",
      "100 3.9860843176858225\n",
      "200 4.81269739100577\n",
      "300 4.6951158841205825\n",
      "400 4.975703724296977\n",
      "500 5.13216882138056\n",
      "600 5.199970886236656\n",
      "700 5.259395331017231\n",
      "800 5.343992961033223\n",
      "900 5.414052266603221\n",
      "1000 5.4665908506934215\n",
      "1100 5.511895073666665\n",
      "1200 5.545966783440463\n",
      "1300 5.57325312774924\n",
      "1400 5.596133194856293\n",
      "1500 5.61382406272503\n",
      "1600 5.628344477179041\n",
      "1700 5.6384501005026095\n",
      "1800 5.649296274143808\n",
      "1900 5.65746110229486\n",
      "2000 5.663452970434378\n",
      "2100 5.66860615440936\n",
      "2200 5.672935427942889\n",
      "2300 5.677257165748358\n",
      "2400 5.679818570169232\n",
      "2500 5.682471177422258\n",
      "2600 5.684813415215558\n",
      "2700 5.686683102258712\n",
      "2800 5.688407544695167\n",
      "2900 5.690512969478732\n",
      "3000 5.691171619429213\n",
      "3100 5.692356594672162\n",
      "3200 5.693286602408591\n",
      "3300 5.694177130415994\n",
      "3400 5.694969825330986\n",
      "3500 5.695674969825404\n",
      "3600 5.696310055684194\n",
      "3700 5.696874652132578\n",
      "3800 5.697359250503325\n",
      "3900 5.697834151320876\n",
      "4000 5.6982590080010596\n",
      "4100 5.6986367823668616\n",
      "4200 5.698975022819695\n",
      "4300 5.699286578845317\n",
      "4400 5.699571014106709\n",
      "4500 5.69982124867056\n",
      "4600 5.7000617747800675\n",
      "4700 5.700280412747588\n",
      "4800 5.700418528660975\n",
      "4900 5.700353576481916\n",
      "5000 5.700828815258433\n",
      "5100 5.700983209466131\n",
      "5200 5.701123089568227\n",
      "5300 5.701256101082663\n",
      "5400 5.701376424228556\n",
      "5500 5.701486512511906\n",
      "5600 5.701591522507158\n",
      "5700 5.701690129027384\n",
      "5800 5.701779946333659\n",
      "5900 5.701864130555919\n",
      "6000 5.701942754331867\n",
      "6100 5.702015170533514\n",
      "6200 5.70208217080426\n",
      "6300 5.702152189492267\n",
      "6400 5.702203468656421\n",
      "6500 5.702258051648414\n",
      "6600 5.702308862364191\n",
      "6700 5.7023561618462395\n",
      "6800 5.702403044111861\n",
      "6900 5.702440829333796\n",
      "7000 5.702480553355429\n",
      "7100 5.702517046018215\n",
      "7200 5.702551213657216\n",
      "7300 5.702583363705003\n",
      "7400 5.702613040454253\n",
      "7500 5.70264112808843\n",
      "7600 5.7026673310152205\n",
      "7700 5.702691895099861\n",
      "7800 5.702715057964269\n",
      "7900 5.7027368187626735\n",
      "8000 5.702756824325604\n",
      "8100 5.702775926794118\n",
      "8200 5.702793872736606\n",
      "8300 5.702810723798393\n",
      "8400 5.702826736548673\n",
      "8500 5.702841408340078\n",
      "8600 5.70285538821804\n",
      "8700 5.702868545868\n",
      "8800 5.702880908564794\n",
      "8900 5.70289228548404\n",
      "9000 5.702903461702476\n",
      "9100 5.702913554394854\n",
      "9200 5.702923282021061\n",
      "9300 5.702932400449413\n",
      "9400 5.702941040755718\n",
      "9500 5.7029490215501255\n",
      "9600 5.70295667727828\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/suyamatatsuhiko/Downloads/2_29_ニューラルネットの単一化.ipynb セル 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W5sZmlsZQ%3D%3D?line=344'>345</a>\u001b[0m         \u001b[39mprint\u001b[39m(epoch,\u001b[39m-\u001b[39mloss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W5sZmlsZQ%3D%3D?line=345'>346</a>\u001b[0m     \u001b[39m#print(f'epoch : {epoch},loss : {-loss.item()}')\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W5sZmlsZQ%3D%3D?line=346'>347</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W5sZmlsZQ%3D%3D?line=351'>352</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/suyamatatsuhiko/Downloads/2_29_%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%81%AE%E5%8D%98%E4%B8%80%E5%8C%96.ipynb#W5sZmlsZQ%3D%3D?line=353'>354</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39msynchronize()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#@title 関数　ストラングル 3\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "#満期の株価\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#満期\n",
    "maturity = 4 # @param\n",
    "\n",
    "#時間間隔\n",
    "dt=1/maturity#@param\n",
    "\n",
    "\n",
    "sigma_ave=0.3 # @param\n",
    "mu_ave=0.05-sigma_ave**2/2#@param\n",
    "S_0 = 100  # @param\n",
    "strike = 120  # @param\n",
    "branches_bin=2#@param\n",
    "\n",
    "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
    "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
    "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
    "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "print(Call_T)\n",
    "for n in np.arange(maturity-1,-1,-1):\n",
    "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "\n",
    "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "init_cost=Call_T[0]\n",
    "\n",
    "\n",
    "\n",
    "#3項モデルでのパラメータを設定する\n",
    "branches = 3  # @param\n",
    "nu=0.005#@param\n",
    "zeta=0.35#@param\n",
    "# 上昇率\n",
    "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_cost\n",
    "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#コールオプションの支払い\n",
    "def call(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(stock_price-strike,0)\n",
    "#プットオプションの支払い\n",
    "def put(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(strike-stock_price,0)\n",
    "#パラメータから確率測度を計算\n",
    "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
    "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
    "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
    "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
    "  return prob\n",
    "import numpy as np\n",
    "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
    "    return x.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "payoff='call'\n",
    "#最適ヘッジの計算\n",
    "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
    "    #初期条件\n",
    "    #maturity : 満期\n",
    "    #branches : 分岐数\n",
    "    #up : 上昇因子\n",
    "    #down : 下降因子\n",
    "    #S_0 : 初期株価\n",
    "    #init_cost : 初期コスト\n",
    "    #prob_matrix : 推移確率\n",
    "    #payoff_func : 支払い関数\n",
    "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
    "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
    "    assert up>1 #上昇因子は1より大きい実数\n",
    "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
    "    assert S_0>=0\n",
    "    assert init_cost>=0\n",
    "    import numpy as np\n",
    "    data = []\n",
    "    delta_S=[]\n",
    "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
    "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
    "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
    "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
    "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
    "\n",
    "    if payoff=='call':\n",
    "      #コール\n",
    "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
    "    if payoff=='strangle':\n",
    "      #ストラングル\n",
    "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    if payoff=='bull':\n",
    "      #ブルスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    elif payoff=='batafrei':\n",
    "      #バタフライスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "      prob_tensor=prob_list[n]\n",
    "      a_n= a_n.unfold(0,branches, 1)\n",
    "      b_n=b_n.unfold(0,branches, 1)\n",
    "      c_n= c_n.unfold(0,branches, 1)\n",
    "      stock_price = stock_price.unfold(0,branches,1)\n",
    "      #条件付き期待値を計算\n",
    "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
    "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
    "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
    "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
    "\n",
    "      stock_price=(stock_price/up)[:,0]\n",
    "      #a, b, cの更新\n",
    "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_n=Cond_Exp_a-a_divide\n",
    "      b_n=Cond_Exp_b-a_b_divide\n",
    "      c_n=Cond_Exp_c-b_divide\n",
    "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
    "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
    "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
    "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
    "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
    "    Hedge_Error\n",
    "    return Hedge_Error,pi_0,init_cost_opt,df\n",
    "\n",
    "\n",
    "\n",
    "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "strike_range =np.arange(80,130,10)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        return (x - mean) / std\n",
    "normalize = Normalize()\n",
    "def tensor_to_standard(input_tensor):\n",
    "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "def decimal_to_base_n(n, base):\n",
    "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, base)\n",
    "        nums.append(str(r))\n",
    "    return int(''.join(reversed(nums)))\n",
    "df=pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for strike in strike_range:\n",
    " \n",
    "    if payoff=='call':\n",
    "        #コール\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "    if payoff=='strangle':\n",
    "        #ストラングル\n",
    "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    if payoff=='bull':\n",
    "        #ブルスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    elif payoff=='batafrei':\n",
    "        #バタフライスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "\n",
    "\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "    init_cost=Call_T[0]\n",
    "    end_epoch = []\n",
    "    prob_list_bust = []\n",
    "    df_weight = pd.DataFrame()\n",
    "\n",
    "    df_pi_0 = pd.DataFrame()\n",
    "    prob_df = []\n",
    "    pi_0s=[]\n",
    "    losses = []\n",
    "    weights = []\n",
    "    grads = []\n",
    "    error_True = []\n",
    "\n",
    "\n",
    "    def call(strike=strike, stock_price=stock_price_T):\n",
    "        stock_price = stock_price_T()\n",
    "        return np.maximum(stock_price - strike, 0)\n",
    "    #Heの初期化\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
    "\n",
    "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
    "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
    "\n",
    "\n",
    "    models = model_params.shape[0]\n",
    "    torch.cuda.seed_all()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input_size = 9\n",
    "    hidden_size = 2**9\n",
    "    output_size = models\n",
    "\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc_add1=nn.Linear(input_size,input_size)\n",
    "            self.fc_add2=nn.Linear(input_size,input_size)\n",
    "            self.layers = nn.Sequential()\n",
    "\n",
    "            # 入力層\n",
    "            #1層\n",
    "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
    "\n",
    "\n",
    "            #2層\n",
    "            activation=nn.ReLU()\n",
    "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu{0}\", activation)\n",
    "            self.layers.add_module(f\"st{0}\", normalize)\n",
    "            units=20\n",
    "            for i in np.arange(1,units,1):\n",
    "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
    "                self.layers.add_module(f\"relu{i}\",activation)\n",
    "                self.layers.add_module(f\"st{i}\", normalize)\n",
    "\n",
    "           \n",
    "\n",
    "            #3層\n",
    "        \n",
    "\n",
    "            #4層\n",
    "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu_final\", activation)\n",
    "\n",
    "\n",
    "            # 出力層\n",
    "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "\n",
    "    net =NN().cuda().double()\n",
    "  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0005) \n",
    "\n",
    "\n",
    "    num_epochs =10**4*5\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
    "        new_weight_tensor = weight_tensor.clone()\n",
    "\n",
    "\n",
    "        for n in np.arange(maturity-1, 0, -1):\n",
    "\n",
    "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
    "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
    "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
    "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
    "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "\n",
    "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
    "\n",
    "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
    "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
    "        weight_tensor = new_weight_tensor\n",
    "\n",
    "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
    "        new_prob_tensor=prob_tensor.clone()\n",
    "        for m in range(models):\n",
    "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
    "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
    "\n",
    "        new_prob_tensor\n",
    "        prob_list=[]\n",
    "        for n in range(new_prob_tensor.shape[0]):\n",
    "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
    "\n",
    "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
    "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
    "        pi_0s.append(pi_0.item())\n",
    "        weights.append(weight_tensor.detach().cpu().numpy())\n",
    "        losses.append(-loss.item())\n",
    "        if epoch % 100==0:\n",
    "            print(epoch,-loss.item())\n",
    "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time=time.perf_counter() - t0\n",
    "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
    "\n",
    "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
    "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
    "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
    "\n",
    "\n",
    "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
    "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
    "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov.csv',index=False)\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # 1万個のデータを準備\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    # lossesの勾配を計算\n",
    "    gradient_losses = np.gradient(losses)\n",
    "\n",
    "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
    "    indices = np.arange(1, len(losses), 100)\n",
    "\n",
    "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
    "    selected_losses = losses[indices]\n",
    "    selected_gradient_losses = gradient_losses[indices]\n",
    "\n",
    "    # lossesとgradient_lossesから最大値を取得\n",
    "    max_loss = np.max(losses)\n",
    "    max_gradient_loss = np.max(gradient_losses)\n",
    "\n",
    "    # 最大値のインデックスを取得\n",
    "    index_max_loss = np.argmax(losses)\n",
    "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
    "\n",
    "    # プロットの作成\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
    "\n",
    "    # gradient_lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
    "\n",
    "    # グラフのタイトルと軸ラベルの設定\n",
    "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
    "                  xaxis_title='エポック数',\n",
    "                  yaxis_title='ヘッジ誤差')\n",
    "\n",
    "    # グラフをHTMLファイルとして保存\n",
    "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
    "\n",
    "    # グラフの表示\n",
    "\n",
    "    step=1\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
    "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
    "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
    "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.12522089 15.6625003   0.          0.          0.        ]\n",
      "0 3.836607737977033\n",
      "10000 5.883557513039648\n",
      "20000 5.883565408707739\n",
      "30000 5.883565454553207\n",
      "40000 5.883565455000507\n",
      "50000 5.883565455042685\n",
      "60000 5.883565455063035\n",
      "70000 5.880492786341506\n",
      "80000 5.77804145222359\n",
      "90000 5.778041453874835\n",
      "処理時間 : 3295.1661597479833,strike : 80,loss : 5.883565455072187\n",
      "0 4.396560835072023\n",
      "10000 10.121338361406117\n",
      "20000 10.121397381217406\n",
      "30000 10.120835089408303\n",
      "40000 10.121275920377002\n",
      "50000 10.121275944090428\n",
      "60000 10.121275944508227\n",
      "70000 10.120515016641207\n",
      "80000 10.120515021807392\n",
      "90000 10.120515021981419\n",
      "処理時間 : 3276.798425633984,strike : 90,loss : 10.122833046557986\n",
      "0 4.308770045030315\n",
      "10000 14.882559269816511\n",
      "20000 14.882616860909081\n",
      "30000 14.882617181267975\n",
      "40000 14.756437568506968\n",
      "50000 14.757871792646753\n",
      "60000 14.864365226082867\n",
      "70000 14.856594771049714\n",
      "80000 14.87507790091982\n",
      "90000 14.867335843180072\n",
      "処理時間 : 3249.7200903639896,strike : 100,loss : 14.882617181883205\n",
      "0 5.050877866869712\n",
      "10000 13.083838977159807\n",
      "20000 13.083860269146484\n",
      "30000 13.08386039158139\n",
      "40000 13.083860392559679\n",
      "50000 13.083860392621595\n",
      "60000 12.784265683455985\n",
      "70000 13.035411177287571\n",
      "80000 13.096721715640662\n",
      "90000 13.077779729984229\n",
      "処理時間 : 3304.859958326997,strike : 110,loss : 13.114351344522476\n",
      "0 11.269464715194971\n",
      "10000 19.687138802830972\n",
      "20000 19.687167932062508\n",
      "30000 19.68716810904263\n",
      "40000 19.54561643186873\n",
      "50000 19.596512289497344\n",
      "60000 19.68276079522753\n",
      "70000 19.682761343737887\n",
      "80000 19.682761358438434\n",
      "90000 19.595921285251258\n",
      "処理時間 : 3342.5018746379938,strike : 120,loss : 19.687168149396122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>64740.0</td>\n",
       "      <td>1.369650e-12</td>\n",
       "      <td>0.846910</td>\n",
       "      <td>5.883565</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5716.0</td>\n",
       "      <td>8.397065e-06</td>\n",
       "      <td>0.706772</td>\n",
       "      <td>10.122833</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>30719.0</td>\n",
       "      <td>3.623477e-11</td>\n",
       "      <td>0.560019</td>\n",
       "      <td>14.882617</td>\n",
       "      <td>3249.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>81675.0</td>\n",
       "      <td>2.356423e-13</td>\n",
       "      <td>0.402624</td>\n",
       "      <td>13.114351</td>\n",
       "      <td>3304.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>37910.0</td>\n",
       "      <td>3.891799e-12</td>\n",
       "      <td>0.249945</td>\n",
       "      <td>19.687168</td>\n",
       "      <td>3342.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1             2         3          4       5    6\n",
       "0   80.0  64740.0  1.369650e-12  0.846910   5.883565  3295.0  0.0\n",
       "0   90.0   5716.0  8.397065e-06  0.706772  10.122833  3276.0  0.0\n",
       "0  100.0  30719.0  3.623477e-11  0.560019  14.882617  3249.0  0.0\n",
       "0  110.0  81675.0  2.356423e-13  0.402624  13.114351  3304.0  0.0\n",
       "0  120.0  37910.0  3.891799e-12  0.249945  19.687168  3342.0  0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#@title 関数　ストラングル 3\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "#満期の株価\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#満期\n",
    "maturity = 4 # @param\n",
    "\n",
    "#時間間隔\n",
    "dt=1/maturity#@param\n",
    "\n",
    "\n",
    "sigma_ave=0.3 # @param\n",
    "mu_ave=0.05-sigma_ave**2/2#@param\n",
    "S_0 = 100  # @param\n",
    "strike = 120  # @param\n",
    "branches_bin=2#@param\n",
    "\n",
    "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
    "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
    "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
    "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "print(Call_T)\n",
    "for n in np.arange(maturity-1,-1,-1):\n",
    "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "\n",
    "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "init_cost=Call_T[0]\n",
    "\n",
    "\n",
    "\n",
    "#3項モデルでのパラメータを設定する\n",
    "branches = 3  # @param\n",
    "nu=0.005#@param\n",
    "zeta=0.35#@param\n",
    "# 上昇率\n",
    "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_cost\n",
    "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#コールオプションの支払い\n",
    "def call(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(stock_price-strike,0)\n",
    "#プットオプションの支払い\n",
    "def put(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(strike-stock_price,0)\n",
    "#パラメータから確率測度を計算\n",
    "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
    "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
    "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
    "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
    "  return prob\n",
    "import numpy as np\n",
    "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
    "    return x.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "payoff='call'\n",
    "#最適ヘッジの計算\n",
    "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
    "    #初期条件\n",
    "    #maturity : 満期\n",
    "    #branches : 分岐数\n",
    "    #up : 上昇因子\n",
    "    #down : 下降因子\n",
    "    #S_0 : 初期株価\n",
    "    #init_cost : 初期コスト\n",
    "    #prob_matrix : 推移確率\n",
    "    #payoff_func : 支払い関数\n",
    "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
    "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
    "    assert up>1 #上昇因子は1より大きい実数\n",
    "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
    "    assert S_0>=0\n",
    "    assert init_cost>=0\n",
    "    import numpy as np\n",
    "    data = []\n",
    "    delta_S=[]\n",
    "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
    "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
    "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
    "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
    "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
    "\n",
    "    if payoff=='call':\n",
    "      #コール\n",
    "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
    "    if payoff=='strangle':\n",
    "      #ストラングル\n",
    "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    if payoff=='bull':\n",
    "      #ブルスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    elif payoff=='batafrei':\n",
    "      #バタフライスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "      prob_tensor=prob_list[n]\n",
    "      a_n= a_n.unfold(0,branches, 1)\n",
    "      b_n=b_n.unfold(0,branches, 1)\n",
    "      c_n= c_n.unfold(0,branches, 1)\n",
    "      stock_price = stock_price.unfold(0,branches,1)\n",
    "      #条件付き期待値を計算\n",
    "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
    "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
    "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
    "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
    "\n",
    "      stock_price=(stock_price/up)[:,0]\n",
    "      #a, b, cの更新\n",
    "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_n=Cond_Exp_a-a_divide\n",
    "      b_n=Cond_Exp_b-a_b_divide\n",
    "      c_n=Cond_Exp_c-b_divide\n",
    "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
    "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
    "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
    "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
    "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
    "    Hedge_Error\n",
    "    return Hedge_Error,pi_0,init_cost_opt,df\n",
    "\n",
    "\n",
    "\n",
    "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "strike_range =np.arange(80,130,10)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        return (x - mean) / std\n",
    "normalize = Normalize()\n",
    "def tensor_to_standard(input_tensor):\n",
    "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "def decimal_to_base_n(n, base):\n",
    "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, base)\n",
    "        nums.append(str(r))\n",
    "    return int(''.join(reversed(nums)))\n",
    "df=pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for strike in strike_range:\n",
    " \n",
    "    if payoff=='call':\n",
    "        #コール\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "    if payoff=='strangle':\n",
    "        #ストラングル\n",
    "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    if payoff=='bull':\n",
    "        #ブルスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    elif payoff=='batafrei':\n",
    "        #バタフライスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "\n",
    "\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "    init_cost=Call_T[0]\n",
    "    end_epoch = []\n",
    "    prob_list_bust = []\n",
    "    df_weight = pd.DataFrame()\n",
    "\n",
    "    df_pi_0 = pd.DataFrame()\n",
    "    prob_df = []\n",
    "    pi_0s=[]\n",
    "    losses = []\n",
    "    weights = []\n",
    "    grads = []\n",
    "    error_True = []\n",
    "\n",
    "\n",
    "    def call(strike=strike, stock_price=stock_price_T):\n",
    "        stock_price = stock_price_T()\n",
    "        return np.maximum(stock_price - strike, 0)\n",
    "    #Heの初期化\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('tanh'))#gain=np.sqrt(2)\n",
    "\n",
    "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
    "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
    "\n",
    "\n",
    "    models = model_params.shape[0]\n",
    "    torch.cuda.seed_all()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input_size = 9\n",
    "    hidden_size = 2**5\n",
    "    output_size = models\n",
    "\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc_add1=nn.Linear(input_size,input_size)\n",
    "            self.fc_add2=nn.Linear(input_size,input_size)\n",
    "            self.layers = nn.Sequential()\n",
    "\n",
    "            # 入力層\n",
    "            #1層\n",
    "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
    "\n",
    "\n",
    "            #2層\n",
    "            activation=nn.Tanh()\n",
    "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu{0}\", activation)\n",
    "            self.layers.add_module(f\"st{0}\", normalize)\n",
    "            units=10\n",
    "            for i in np.arange(1,units,1):\n",
    "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
    "                self.layers.add_module(f\"relu{i}\",activation)\n",
    "                self.layers.add_module(f\"st{i}\", normalize)\n",
    "\n",
    "           \n",
    "\n",
    "            #3層\n",
    "        \n",
    "\n",
    "            #4層\n",
    "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu_final\", activation)\n",
    "\n",
    "\n",
    "            # 出力層\n",
    "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "\n",
    "    net =NN().cuda().double()\n",
    "  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0007) #学習率が支配的な感じはある\n",
    "\n",
    "\n",
    "    num_epochs =10**5\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
    "        new_weight_tensor = weight_tensor.clone()\n",
    "\n",
    "\n",
    "        for n in np.arange(maturity-1, 0, -1):\n",
    "\n",
    "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
    "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
    "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
    "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
    "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "\n",
    "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
    "\n",
    "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
    "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
    "        weight_tensor = new_weight_tensor\n",
    "\n",
    "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
    "        new_prob_tensor=prob_tensor.clone()\n",
    "        for m in range(models):\n",
    "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
    "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
    "\n",
    "        new_prob_tensor\n",
    "        prob_list=[]\n",
    "        for n in range(new_prob_tensor.shape[0]):\n",
    "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
    "\n",
    "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
    "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
    "        pi_0s.append(pi_0.item())\n",
    "        weights.append(weight_tensor.detach().cpu().numpy())\n",
    "        losses.append(-loss.item())\n",
    "        if epoch % 10000==0:\n",
    "            print(epoch,-loss.item())\n",
    "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time=time.perf_counter() - t0\n",
    "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
    "\n",
    "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
    "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
    "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
    "\n",
    "\n",
    "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
    "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
    "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov.csv',index=False)\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # 1万個のデータを準備\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    # lossesの勾配を計算\n",
    "    gradient_losses = np.gradient(losses)\n",
    "\n",
    "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
    "    indices = np.arange(1, len(losses), 100)\n",
    "\n",
    "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
    "    selected_losses = losses[indices]\n",
    "    selected_gradient_losses = gradient_losses[indices]\n",
    "\n",
    "    # lossesとgradient_lossesから最大値を取得\n",
    "    max_loss = np.max(losses)\n",
    "    max_gradient_loss = np.max(gradient_losses)\n",
    "\n",
    "    # 最大値のインデックスを取得\n",
    "    index_max_loss = np.argmax(losses)\n",
    "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
    "\n",
    "    # プロットの作成\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
    "\n",
    "    # gradient_lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
    "\n",
    "    # グラフのタイトルと軸ラベルの設定\n",
    "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
    "                  xaxis_title='エポック数',\n",
    "                  yaxis_title='ヘッジ誤差')\n",
    "\n",
    "    # グラフをHTMLファイルとして保存\n",
    "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
    "\n",
    "    # グラフの表示\n",
    "\n",
    "    step=1\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
    "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
    "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
    "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.12522089 15.6625003   0.          0.          0.        ]\n",
      "0 3.836607737977033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@title 関数　ストラングル 3\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "#満期の株価\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#満期\n",
    "maturity = 4 # @param\n",
    "\n",
    "#時間間隔\n",
    "dt=1/maturity#@param\n",
    "\n",
    "\n",
    "sigma_ave=0.3 # @param\n",
    "mu_ave=0.05-sigma_ave**2/2#@param\n",
    "S_0 = 100  # @param\n",
    "strike = 120  # @param\n",
    "branches_bin=2#@param\n",
    "\n",
    "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
    "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
    "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
    "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "print(Call_T)\n",
    "for n in np.arange(maturity-1,-1,-1):\n",
    "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "\n",
    "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "init_cost=Call_T[0]\n",
    "\n",
    "\n",
    "\n",
    "#3項モデルでのパラメータを設定する\n",
    "branches = 3  # @param\n",
    "nu=0.005#@param\n",
    "zeta=0.35#@param\n",
    "# 上昇率\n",
    "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
    "# 下落率\n",
    "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "init_cost\n",
    "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
    "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
    "        assert np.min(stock_price)>=0\n",
    "        return stock_price\n",
    "#コールオプションの支払い\n",
    "def call(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(stock_price-strike,0)\n",
    "#プットオプションの支払い\n",
    "def put(strike=strike,stock_price=stock_price_T):\n",
    "    stock_price=stock_price_T()\n",
    "    return np.maximum(strike-stock_price,0)\n",
    "#パラメータから確率測度を計算\n",
    "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
    "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
    "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
    "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
    "  return prob\n",
    "import numpy as np\n",
    "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
    "    return x.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "payoff='call'\n",
    "#最適ヘッジの計算\n",
    "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
    "    #初期条件\n",
    "    #maturity : 満期\n",
    "    #branches : 分岐数\n",
    "    #up : 上昇因子\n",
    "    #down : 下降因子\n",
    "    #S_0 : 初期株価\n",
    "    #init_cost : 初期コスト\n",
    "    #prob_matrix : 推移確率\n",
    "    #payoff_func : 支払い関数\n",
    "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
    "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
    "    assert up>1 #上昇因子は1より大きい実数\n",
    "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
    "    assert S_0>=0\n",
    "    assert init_cost>=0\n",
    "    import numpy as np\n",
    "    data = []\n",
    "    delta_S=[]\n",
    "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
    "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
    "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
    "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
    "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
    "\n",
    "    if payoff=='call':\n",
    "      #コール\n",
    "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
    "    if payoff=='strangle':\n",
    "      #ストラングル\n",
    "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    if payoff=='bull':\n",
    "      #ブルスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    elif payoff=='batafrei':\n",
    "      #バタフライスプレッド\n",
    "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
    "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "      prob_tensor=prob_list[n]\n",
    "      a_n= a_n.unfold(0,branches, 1)\n",
    "      b_n=b_n.unfold(0,branches, 1)\n",
    "      c_n= c_n.unfold(0,branches, 1)\n",
    "      stock_price = stock_price.unfold(0,branches,1)\n",
    "      #条件付き期待値を計算\n",
    "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
    "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
    "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
    "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
    "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
    "\n",
    "      stock_price=(stock_price/up)[:,0]\n",
    "      #a, b, cの更新\n",
    "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
    "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
    "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
    "      a_n=Cond_Exp_a-a_divide\n",
    "      b_n=Cond_Exp_b-a_b_divide\n",
    "      c_n=Cond_Exp_c-b_divide\n",
    "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
    "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
    "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
    "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
    "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
    "    Hedge_Error\n",
    "    return Hedge_Error,pi_0,init_cost_opt,df\n",
    "\n",
    "\n",
    "\n",
    "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "strike_range =np.arange(80,130,10)\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, dim=0, keepdim=True)\n",
    "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        return (x - mean) / std\n",
    "normalize = Normalize()\n",
    "def tensor_to_standard(input_tensor):\n",
    "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "def decimal_to_base_n(n, base):\n",
    "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    nums = []\n",
    "    while n:\n",
    "        n, r = divmod(n, base)\n",
    "        nums.append(str(r))\n",
    "    return int(''.join(reversed(nums)))\n",
    "df=pd.DataFrame()\n",
    "from tqdm import tqdm\n",
    "for strike in strike_range:\n",
    " \n",
    "    if payoff=='call':\n",
    "        #コール\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
    "    if payoff=='strangle':\n",
    "        #ストラングル\n",
    "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    if payoff=='bull':\n",
    "        #ブルスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "    elif payoff=='batafrei':\n",
    "        #バタフライスプレッド\n",
    "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
    "\n",
    "\n",
    "    for n in np.arange(maturity-1,-1,-1):\n",
    "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
    "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
    "    init_cost=Call_T[0]\n",
    "    end_epoch = []\n",
    "    prob_list_bust = []\n",
    "    df_weight = pd.DataFrame()\n",
    "\n",
    "    df_pi_0 = pd.DataFrame()\n",
    "    prob_df = []\n",
    "    pi_0s=[]\n",
    "    losses = []\n",
    "    weights = []\n",
    "    grads = []\n",
    "    error_True = []\n",
    "\n",
    "\n",
    "    def call(strike=strike, stock_price=stock_price_T):\n",
    "        stock_price = stock_price_T()\n",
    "        return np.maximum(stock_price - strike, 0)\n",
    "    #Heの初期化\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('tanh'))#gain=np.sqrt(2)\n",
    "\n",
    "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
    "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
    "\n",
    "\n",
    "    models = model_params.shape[0]\n",
    "    torch.cuda.seed_all()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    input_size = 9\n",
    "    hidden_size = 2**5\n",
    "    output_size = models\n",
    "\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc_add1=nn.Linear(input_size,input_size)\n",
    "            self.fc_add2=nn.Linear(input_size,input_size)\n",
    "            self.layers = nn.Sequential()\n",
    "\n",
    "            # 入力層\n",
    "            #1層\n",
    "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
    "\n",
    "\n",
    "            #2層\n",
    "            activation=nn.Tanh()\n",
    "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu{0}\", activation)\n",
    "            self.layers.add_module(f\"st{0}\", normalize)\n",
    "            units=10\n",
    "            for i in np.arange(1,units,1):\n",
    "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
    "                self.layers.add_module(f\"relu{i}\",activation)\n",
    "                self.layers.add_module(f\"st{i}\", normalize)\n",
    "\n",
    "           \n",
    "\n",
    "            #3層\n",
    "        \n",
    "\n",
    "            #4層\n",
    "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
    "            self.layers.add_module(f\"relu_final\", activation)\n",
    "\n",
    "\n",
    "            # 出力層\n",
    "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.layers(x)\n",
    "\n",
    "\n",
    "    net =NN().cuda().double()\n",
    "  \n",
    "    net.apply(init_weights)\n",
    "\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0008) #学習率が支配的な感じはある\n",
    "\n",
    "\n",
    "    num_epochs =10**5\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
    "        new_weight_tensor = weight_tensor.clone()\n",
    "\n",
    "\n",
    "        for n in np.arange(maturity-1, 0, -1):\n",
    "\n",
    "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
    "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
    "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
    "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
    "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "\n",
    "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
    "\n",
    "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
    "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
    "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
    "        weight_tensor = new_weight_tensor\n",
    "\n",
    "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
    "        new_prob_tensor=prob_tensor.clone()\n",
    "        for m in range(models):\n",
    "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
    "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
    "\n",
    "        new_prob_tensor\n",
    "        prob_list=[]\n",
    "        for n in range(new_prob_tensor.shape[0]):\n",
    "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
    "\n",
    "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
    "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
    "        pi_0s.append(pi_0.item())\n",
    "        weights.append(weight_tensor.detach().cpu().numpy())\n",
    "        losses.append(-loss.item())\n",
    "        if epoch % 10000==0:\n",
    "            print(epoch,-loss.item())\n",
    "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_time=time.perf_counter() - t0\n",
    "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
    "\n",
    "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
    "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
    "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
    "\n",
    "\n",
    "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
    "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
    "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov_08.csv',index=False)\n",
    "    import numpy as np\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # 1万個のデータを準備\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    # lossesの勾配を計算\n",
    "    gradient_losses = np.gradient(losses)\n",
    "\n",
    "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
    "    indices = np.arange(1, len(losses), 100)\n",
    "\n",
    "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
    "    selected_losses = losses[indices]\n",
    "    selected_gradient_losses = gradient_losses[indices]\n",
    "\n",
    "    # lossesとgradient_lossesから最大値を取得\n",
    "    max_loss = np.max(losses)\n",
    "    max_gradient_loss = np.max(gradient_losses)\n",
    "\n",
    "    # 最大値のインデックスを取得\n",
    "    index_max_loss = np.argmax(losses)\n",
    "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
    "\n",
    "    # プロットの作成\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
    "\n",
    "    # gradient_lossesの全データと抽出したデータをプロット\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
    "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
    "\n",
    "    # グラフのタイトルと軸ラベルの設定\n",
    "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
    "                  xaxis_title='エポック数',\n",
    "                  yaxis_title='ヘッジ誤差')\n",
    "\n",
    "    # グラフをHTMLファイルとして保存\n",
    "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
    "\n",
    "    # グラフの表示\n",
    "\n",
    "    step=1\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
    "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
    "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
    "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
    "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
    "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
    "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
