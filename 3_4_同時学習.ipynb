{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDLMZQCFQXzNgT6GrVME+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatsuhiko-suyama/colab_pub/blob/main/3_4_%E5%90%8C%E6%99%82%E5%AD%A6%E7%BF%92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uio_g6lkU16",
        "outputId": "a9165f33-0fcf-474a-84f2-f6432ec0b47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.12\n",
            "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12) (4.10.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize_matplotlib\n",
        "!pip install plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1LOOgzekfD2",
        "outputId": "63c9eb7e-d739-4354-aa44-73f5169a69e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: japanize_matplotlib in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from japanize_matplotlib) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title 関数　ストラングル 3\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 4 # @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 120  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
        "        assert np.min(stock_price)>=0\n",
        "        return stock_price\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "print(Call_T)\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
        "\n",
        "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "init_cost\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
        "        assert np.min(stock_price)>=0\n",
        "        return stock_price\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "import numpy as np\n",
        "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
        "    return x.cpu().detach().numpy().reshape(-1)\n",
        "\n",
        "payoff='call'\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    import numpy as np\n",
        "    data = []\n",
        "    delta_S=[]\n",
        "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
        "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
        "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
        "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
        "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
        "\n",
        "    if payoff=='call':\n",
        "      #コール\n",
        "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    if payoff=='strangle':\n",
        "      #ストラングル\n",
        "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    if payoff=='bull':\n",
        "      #ブルスプレッド\n",
        "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    elif payoff=='batafrei':\n",
        "      #バタフライスプレッド\n",
        "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "      prob_tensor=prob_list[n]\n",
        "      a_n= a_n.unfold(0,branches, 1)\n",
        "      b_n=b_n.unfold(0,branches, 1)\n",
        "      c_n= c_n.unfold(0,branches, 1)\n",
        "      stock_price = stock_price.unfold(0,branches,1)\n",
        "      #条件付き期待値を計算\n",
        "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "\n",
        "      stock_price=(stock_price/up)[:,0]\n",
        "      #a, b, cの更新\n",
        "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "      a_n=Cond_Exp_a-a_divide\n",
        "      b_n=Cond_Exp_b-a_b_divide\n",
        "      c_n=Cond_Exp_c-b_divide\n",
        "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
        "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
        "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
        "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
        "    Hedge_Error\n",
        "    return Hedge_Error,pi_0,init_cost_opt,df\n",
        "\n",
        "\n",
        "\n",
        "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[80]\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "\n",
        "    if payoff=='call':\n",
        "        #コール\n",
        "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    if payoff=='strangle':\n",
        "        #ストラングル\n",
        "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    if payoff=='bull':\n",
        "        #ブルスプレッド\n",
        "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff=='batafrei':\n",
        "        #バタフライスプレッド\n",
        "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "\n",
        "\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
        "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('leaky_relu',0.1))#gain=np.sqrt(2)\n",
        "\n",
        "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 2**5\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            activation=nn.LeakyReLU(0.1)\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", activation)\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "            units=10\n",
        "            for i in np.arange(1,units,1):\n",
        "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
        "                self.layers.add_module(f\"relu{i}\",activation)\n",
        "                self.layers.add_module(f\"st{i}\", normalize)\n",
        "\n",
        "\n",
        "\n",
        "            #3層\n",
        "\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu_final\", activation)\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    net =NN().cuda().double()\n",
        "\n",
        "    net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.00001) #学習率が支配的な感じはある\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
        "            input_tensor=torch.concat([current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,0,0,0,1,1,1],[0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        if epoch % 1000==0:\n",
        "            print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
        "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov_08.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "lQKnO4N5Sz3Z",
        "outputId": "751d7dac-ed7c-4da1-98fd-dc54389499a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[63.12522089 15.6625003   0.          0.          0.        ]\n",
            "0 1.6587105922816363\n",
            "1000 4.724999435972336\n",
            "2000 4.854453917553428\n",
            "3000 4.925735030523242\n",
            "4000 4.952421074606832\n",
            "5000 4.972907827664926\n",
            "6000 4.991731224112186\n",
            "7000 5.013359129202286\n",
            "8000 5.038260851431801\n",
            "9000 5.074152046155859\n",
            "10000 5.1158875331886975\n",
            "11000 5.154397494692603\n",
            "12000 5.199784757346606\n",
            "13000 5.24978370518636\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b685e25cf877>\u001b[0m in \u001b[0;36m<cell line: 198>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcalculate_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaturity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpayoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mpi_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculate_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaturity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpayoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0mpi_0s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-b685e25cf877>\u001b[0m in \u001b[0;36mcalculate_table\u001b[0;34m(maturity, branches, up, down, S_0, init_cost, prob_list, strike, payoff)\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0ma_b_divide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCond_Exp_a_Delta_S\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mCond_Exp_b_Delta_S\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCond_Exp_a_Delta_S_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0ma_b_divide\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCond_Exp_a_Delta_S_sq\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0mb_divide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCond_Exp_b_Delta_S\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCond_Exp_a_Delta_S_sq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m       \u001b[0mb_divide\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCond_Exp_a_Delta_S_sq\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0ma_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCond_Exp_a\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma_divide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title 関数　ストラングル 3\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 4 # @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 120  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
        "        assert np.min(stock_price)>=0\n",
        "        return stock_price\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "print(Call_T)\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "  for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
        "\n",
        "    Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "dt=1/maturity#@param\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "init_cost\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
        "        assert np.min(stock_price)>=0\n",
        "        return stock_price\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "import numpy as np\n",
        "def to_numpy(x: torch.Tensor) -> np.ndarray:\n",
        "    return x.cpu().detach().numpy().reshape(-1)\n",
        "\n",
        "payoff='call'\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike,payoff):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    import numpy as np\n",
        "    def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "        stock_price=np.array(S_0 * up ** maturity * down ** np.arange(0, (branches - 1) * maturity + 1, 1),dtype=np.float64)\n",
        "        assert np.min(stock_price)>=0\n",
        "        return stock_price\n",
        "    data = []\n",
        "    delta_S=[]\n",
        "    df=pd.DataFrame(columns=['a_n', 'b_n', 'c_n','stock_price', 'Cond_Exp_a', 'Cond_Exp_a_Delta_S', 'Cond_Exp_a_Delta_S_sq', \\\n",
        "                              'Cond_Exp_b', 'Cond_Exp_b_Delta_S','Cond_Exp_c','(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq', \\\n",
        "                              '(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq','(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq'])\n",
        "    stock_price = torch.from_numpy(stock_price_T()).cuda()\n",
        "    a_n = torch.from_numpy(np.ones((branches - 1) * maturity + 1)).cuda()\n",
        "\n",
        "    if payoff=='call':\n",
        "      #コール\n",
        "      b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "      c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    if payoff=='strangle':\n",
        "      #ストラングル\n",
        "      b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "      c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    if payoff=='bull':\n",
        "      #ブルスプレッド\n",
        "      b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    elif payoff=='batafrei':\n",
        "      #バタフライスプレッド\n",
        "      b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "      c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "      prob_tensor=prob_list[n]\n",
        "      a_n= a_n.unfold(0,branches, 1)\n",
        "      b_n=b_n.unfold(0,branches, 1)\n",
        "      c_n= c_n.unfold(0,branches, 1)\n",
        "      stock_price = stock_price.unfold(0,branches,1)\n",
        "      #条件付き期待値を計算\n",
        "      Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "      Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "      Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "      Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "      Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "      Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "\n",
        "      stock_price=(stock_price/up)[:,0]\n",
        "      #a, b, cの更新\n",
        "      a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "      a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "      a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "      a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "      b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "      b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "      a_n=Cond_Exp_a-a_divide\n",
        "      b_n=Cond_Exp_b-a_b_divide\n",
        "      c_n=Cond_Exp_c-b_divide\n",
        "    df=pd.concat([df,pd.DataFrame({'a_n' :to_numpy(a_n),'b_n':to_numpy(b_n),'c_n': to_numpy(c_n), 'stock_price': to_numpy(stock_price), 'Cond_Exp_a': to_numpy(Cond_Exp_a), 'Cond_Exp_a_Delta_S': to_numpy(Cond_Exp_a_Delta_S), 'Cond_Exp_a_Delta_S_sq': to_numpy(Cond_Exp_a_Delta_S_sq), 'Cond_Exp_b': to_numpy(Cond_Exp_b), 'Cond_Exp_b_Delta_S': to_numpy(Cond_Exp_b_Delta_S), 'Cond_Exp_c': to_numpy(Cond_Exp_c),\n",
        "                         '(Cond_Exp_a_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)**2/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_a_Delta_S)(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_a_Delta_S)*(Cond_Exp_b_Delta_S)/Cond_Exp_a_Delta_S_sq),'(Cond_Exp_b_Delta_S)^2/Cond_Exp_a_Delta_S_sq' : to_numpy((Cond_Exp_b_Delta_S)**2/Cond_Exp_a_Delta_S_sq)})], ignore_index=True)\n",
        "    Hedge_Error = a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0 = Cond_Exp_b_Delta_S/Cond_Exp_a_Delta_S_sq-init_cost*Cond_Exp_a_Delta_S/Cond_Exp_a_Delta_S_sq\n",
        "    init_cost_opt=df.loc[len(df)-1, 'b_n']/df.loc[len(df)-1, 'a_n']\n",
        "    Hedge_Error\n",
        "    return Hedge_Error,pi_0,init_cost_opt,df\n",
        "\n",
        "\n",
        "\n",
        "#期ごとのNN 2モデル, 多層化 これに決めた　ストラングル 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[80,90,100,110,120]\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "\n",
        "    if payoff=='call':\n",
        "        #コール\n",
        "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    if payoff=='strangle':\n",
        "        #ストラングル\n",
        "        Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    if payoff=='bull':\n",
        "        #ブルスプレッド\n",
        "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff=='batafrei':\n",
        "        #バタフライスプレッド\n",
        "        Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "\n",
        "\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        for i in np.arange(0, (branches_bin - 1) * n + 1, 1):\n",
        "            Call_T[i]=Call_T[i : i+branches_bin]@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('leaky_relu',0.1))#gain=np.sqrt(2)\n",
        "\n",
        "    #model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25],[0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 10\n",
        "    hidden_size = 2**5\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            activation=nn.LeakyReLU(0.1)\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", activation)\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "            units=10\n",
        "            for i in np.arange(1,units,1):\n",
        "                self.layers.add_module(f\"fc{i}\", nn.Linear(hidden_size,hidden_size))\n",
        "                self.layers.add_module(f\"relu{i}\",activation)\n",
        "                self.layers.add_module(f\"st{i}\", normalize)\n",
        "\n",
        "\n",
        "\n",
        "            #3層\n",
        "\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc_final\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu_final\", activation)\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    net =NN().cuda().double()\n",
        "\n",
        "    net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.00001) #学習率が支配的な感じはある\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
        "            time_span=(torch.ones_like(S)*dt).reshape(-1,1)\n",
        "            input_tensor=torch.concat([time_span,current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[dt,0,0,0,0,0,0,1,1,1],[dt,0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        if epoch % 1000==0:\n",
        "            print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],\\\n",
        "                                    int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_Markov_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}_hidden_size_{hidden_size}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_hidden_size_{hidden_size}_Markov_08.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "W0GyZTxDZu6N",
        "outputId": "a85890d8-b77b-4ecf-8beb-f6af7a5f6a79"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[63.12522089 15.6625003   0.          0.          0.        ]\n",
            "0 2.227315882708126\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-61181419eb88>\u001b[0m in \u001b[0;36m<cell line: 202>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m#print(f'epoch : {epoch},loss : {-loss.item()}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "net =NN().cuda().double()\n",
        "net.apply(init_weights)\n",
        "loss=torch.zeros(1).cuda()\n",
        "num_epochs=10**4\n",
        "losses=[]\n",
        "for epoch in range(num_epochs):\n",
        "  optimizer.zero_grad()\n",
        "  loss=torch.zeros(1).cuda()\n",
        "  for maturity in [3,4]:\n",
        "    dt=1/maturity#@param\n",
        "    #3項モデルでのパラメータを設定する\n",
        "    branches = 3  # @param\n",
        "    nu=0.005#@param\n",
        "    zeta=0.35#@param\n",
        "    # 上昇率\n",
        "    up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "    # 下落率\n",
        "    down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "    weight_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, model_params.shape[0], requires_grad=True).cuda()\n",
        "    new_weight_tensor = weight_tensor.clone()\n",
        "    for n in np.arange(maturity-1, 0, -1):\n",
        "      S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "      current_time=(torch.ones_like(S)*n*dt).reshape(-1,1)\n",
        "      time_span=(torch.ones_like(S)*dt).reshape(-1,1)\n",
        "      input_tensor=torch.concat([time_span,current_time,current_time**2,current_time**3,torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5],dim=1)\n",
        "      ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "      new_weight_tensor[n][0:(branches-1)*(n+1)-1]=nn.Softmax(dim=1)(net(ST_input_tensor.cuda().double()))\n",
        "\n",
        "    input_tensor=torch.tensor([[dt,0,0,0,0,0,0,1,1,1],[dt,0,0,0,0,0,0,1,1,1]]).cuda().double()\n",
        "    ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "    new_weight_tensor[0][0]=nn.Softmax(dim=1)(net(ST_input_tensor.double()))[0]\n",
        "    weight_tensor = new_weight_tensor\n",
        "\n",
        "    prob_tensor = torch.zeros(maturity, (branches-1) * maturity - 1, branches, requires_grad=True).cuda().double()\n",
        "    new_prob_tensor=prob_tensor.clone()\n",
        "    for m in range(models):\n",
        "      new_prob_tensor=new_prob_tensor+torch.ones(maturity, (branches-1)*maturity-1, branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,(branches-1)*maturity-1,1)\n",
        "\n",
        "    new_prob_tensor\n",
        "    prob_list=[]\n",
        "    for n in range(new_prob_tensor.shape[0]):\n",
        "      prob_list.append(new_prob_tensor[n][0:(branches-1)*n+1].reshape((branches-1)*n+1,branches))\n",
        "\n",
        "    loss += -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike,payoff)[0]\n",
        "  #print(f'ヘッジ誤差 : {loss}')\n",
        "  losses.append(-loss.item())\n",
        "\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "np.max(losses)\n"
      ],
      "metadata": {
        "id": "LKsps54lsbby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(losses)"
      ],
      "metadata": {
        "id": "lKLEMfBl5Suj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}